"""
ìŠ¤íŠ¸ë¦¬ë° í¬ë§·í„°

ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ì„ ìœ„í•œ í¬ë§·í„°ì…ë‹ˆë‹¤.
"""

import logging
from typing import Any, Dict, List, Optional

from .options.formatting_options import FormattingOptions


class StreamingFormatter:
    """
    ìŠ¤íŠ¸ë¦¬ë° í¬ë§·í„°

    ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ì— ì í•©í•œ í˜•íƒœë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤.
    """

    def __init__(self, options: Optional[FormattingOptions] = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° í¬ë§·í„° ì´ˆê¸°í™”

        Args:
            options: í¬ë§·íŒ… ì˜µì…˜
        """
        self.logger = logging.getLogger(__name__)
        self.options = options or FormattingOptions()

    def format_for_streaming(self, validation_result) -> List[Dict[str, Any]]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìš© ì²­í¬ë“¤ë¡œ í¬ë§·íŒ…

        Args:
            validation_result: ValidationResult ê°ì²´

        Returns:
            ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            chunks = []

            # 1. í—¤ë” ì²­í¬
            chunks.append(self._create_header_chunk(validation_result))

            # 2. ê¸°ë³¸ ì •ë³´ ì²­í¬
            chunks.append(self._create_basic_info_chunk(validation_result))

            # 3. ì´ìŠˆ ì •ë³´ ì²­í¬ë“¤
            if hasattr(validation_result, 'issues') and validation_result.issues:
                chunks.extend(self._create_issues_chunks(validation_result.issues))

            # 4. êµ¬ì¡° ì •ë³´ ì²­í¬
            if hasattr(validation_result, 'structure'):
                chunks.append(self._create_structure_chunk(validation_result.structure))

            # 5. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²­í¬
            if hasattr(validation_result, 'performance_metrics'):
                chunks.append(
                    self._create_performance_chunk(
                        validation_result.performance_metrics
                    )
                )

            # 6. í’ˆì§ˆ ë©”íŠ¸ë¦­ ì²­í¬
            if hasattr(validation_result, 'quality_metrics'):
                chunks.append(
                    self._create_quality_chunk(validation_result.quality_metrics)
                )

            # 7. ì™„ë£Œ ì²­í¬
            chunks.append(self._create_completion_chunk(validation_result))

            self.logger.debug(f"ìŠ¤íŠ¸ë¦¬ë° í¬ë§·íŒ… ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
            return chunks

        except Exception as e:
            self.logger.error(f"ìŠ¤íŠ¸ë¦¬ë° í¬ë§·íŒ… ì˜¤ë¥˜: {str(e)}")
            return [self._create_error_chunk(str(e))]

    def _create_header_chunk(self, validation_result) -> Dict[str, Any]:
        """í—¤ë” ì²­í¬ ìƒì„±"""
        return {
            "type": "header",
            "content": f"ğŸ“Š ë£° ë¶„ì„ ê²°ê³¼ - {validation_result.report_metadata.analysis_timestamp}",
            "timestamp": validation_result.report_metadata.analysis_timestamp,
            "progress": 0.0,
            "metadata": {
                "rule_id": getattr(validation_result, 'rule_id', 'unknown'),
                "analysis_version": str(
                    validation_result.report_metadata.analysis_version
                ),
            },
        }

    def _create_basic_info_chunk(self, validation_result) -> Dict[str, Any]:
        """ê¸°ë³¸ ì •ë³´ ì²­í¬ ìƒì„±"""
        return {
            "type": "basic_info",
            "content": f"""
âœ… ìœ íš¨ì„±: {'ìœ íš¨í•¨' if validation_result.is_valid else 'ìœ íš¨í•˜ì§€ ì•ŠìŒ'}
ğŸ“ ìš”ì•½: {validation_result.summary or 'ìš”ì•½ ì—†ìŒ'}
ğŸš¨ ì´ ì´ìŠˆ: {validation_result.get_total_issues()}ê°œ
âš ï¸ ì¹˜ëª…ì  ì´ìŠˆ: {len(validation_result.get_critical_issues()) if hasattr(validation_result.get_critical_issues(), '__len__') else 0}ê°œ
ğŸ“ˆ ë³µì¡ë„ ì ìˆ˜: {str(validation_result.complexity_score)}/100
""",
            "timestamp": validation_result.report_metadata.analysis_timestamp,
            "progress": 0.1,
            "metadata": {
                "is_valid": validation_result.is_valid,
                "total_issues": validation_result.get_total_issues(),
                "critical_issues": (
                    len(validation_result.get_critical_issues())
                    if hasattr(validation_result.get_critical_issues(), '__len__')
                    else 0
                ),
            },
        }

    def _create_issues_chunks(self, issues) -> List[Dict[str, Any]]:
        """ì´ìŠˆ ì •ë³´ ì²­í¬ë“¤ ìƒì„±"""
        chunks = []

        for i, issue in enumerate(issues):
            chunk = {
                "type": "issue",
                "content": f"""
ğŸš¨ ì´ìŠˆ {i+1}: {issue.issue_type}
   ì‹¬ê°ë„: {issue.severity}
   ì„¤ëª…: {issue.explanation}
   ì œì•ˆ: {issue.suggestion or 'ì œì•ˆì‚¬í•­ ì—†ìŒ'}
""",
                "timestamp": (
                    issue.detected_at.isoformat()
                    if hasattr(issue.detected_at, 'isoformat')
                    else str(issue.detected_at)
                ),
                "progress": 0.2 + (i * 0.1),
                "metadata": {
                    "issue_type": issue.issue_type,
                    "severity": issue.severity,
                    "index": i,
                },
            }
            chunks.append(chunk)

        return chunks

    def _create_structure_chunk(self, structure) -> Dict[str, Any]:
        """êµ¬ì¡° ì •ë³´ ì²­í¬ ìƒì„±"""
        return {
            "type": "structure",
            "content": f"""
ğŸ—ï¸ êµ¬ì¡° ë¶„ì„
   ìµœëŒ€ ê¹Šì´: {str(structure.depth)}
   ì¡°ê±´ ê°œìˆ˜: {str(structure.condition_count)}
   ì•¡ì…˜ ê°œìˆ˜: {str(structure.action_count)}
   ë³µì¡ë„ ì ìˆ˜: {str(structure.complexity_score)}/100
   íŒ¨í„´: {', '.join(structure.detected_patterns) if structure.detected_patterns and hasattr(structure.detected_patterns, '__iter__') else 'ì—†ìŒ'}
""",
            "timestamp": "now",
            "progress": 0.7,
            "metadata": {
                "depth": structure.depth,
                "complexity_score": structure.complexity_score,
                "pattern_count": (
                    len(structure.detected_patterns)
                    if hasattr(structure.detected_patterns, '__len__')
                    else 0
                ),
            },
        }

    def _create_performance_chunk(self, performance) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²­í¬ ìƒì„±"""
        return {
            "type": "performance",
            "content": f"""
âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­
   ì„±ëŠ¥ ì ìˆ˜: {str(performance.performance_score)}/100
   ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: {str(performance.estimated_execution_time_ms)}ms
   ë³µì¡ë„ ë“±ê¸‰: {str(performance.complexity_rating)}
   ìµœì í™” ì œì•ˆ: {len(performance.optimization_suggestions) if hasattr(performance.optimization_suggestions, '__len__') else 0}ê°œ
""",
            "timestamp": "now",
            "progress": 0.8,
            "metadata": {
                "performance_score": performance.performance_score,
                "execution_time": performance.estimated_execution_time_ms,
                "optimization_count": (
                    len(performance.optimization_suggestions)
                    if hasattr(performance.optimization_suggestions, '__len__')
                    else 0
                ),
            },
        }

    def _create_quality_chunk(self, quality) -> Dict[str, Any]:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì²­í¬ ìƒì„±"""
        return {
            "type": "quality",
            "content": f"""
ğŸ¯ í’ˆì§ˆ ë©”íŠ¸ë¦­
   ì „ì²´ ì ìˆ˜: {str(quality.overall_score)}/100
   í’ˆì§ˆ ë“±ê¸‰: {str(quality.quality_grade)}
   ìœ ì§€ë³´ìˆ˜ì„±: {str(quality.maintainability_score)}/100
   ê°€ë…ì„±: {str(quality.readability_score)}/100
   ì™„ì„±ë„: {str(quality.completeness_score)}/100
   ì¼ê´€ì„±: {str(quality.consistency_score)}/100
""",
            "timestamp": "now",
            "progress": 0.9,
            "metadata": {
                "overall_score": quality.overall_score,
                "quality_grade": quality.quality_grade,
                "maintainability": quality.maintainability_score,
            },
        }

    def _create_completion_chunk(self, validation_result) -> Dict[str, Any]:
        """ì™„ë£Œ ì²­í¬ ìƒì„±"""
        return {
            "type": "completion",
            "content": f"""
âœ… ë¶„ì„ ì™„ë£Œ!
   ì´ ì†Œìš” ì‹œê°„: {validation_result.report_metadata.report_generation_time:.2f}ì´ˆ
   ìƒì„±ì: {validation_result.report_metadata.report_generated_by}
   í™˜ê²½: {validation_result.report_metadata.environment}
""",
            "timestamp": validation_result.report_metadata.analysis_timestamp,
            "progress": 1.0,
            "metadata": {
                "generation_time": validation_result.report_metadata.report_generation_time,
                "generated_by": validation_result.report_metadata.report_generated_by,
                "status": "completed",
            },
        }

    def _create_error_chunk(self, error_message: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ì²­í¬ ìƒì„±"""
        return {
            "type": "error",
            "content": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {error_message}",
            "timestamp": "now",
            "progress": 1.0,
            "metadata": {
                "error": True,
                "error_message": error_message,
                "status": "error",
            },
        }

    def get_chunk_count(self, validation_result) -> int:
        """
        ì˜ˆìƒ ì²­í¬ ê°œìˆ˜ ë°˜í™˜

        Args:
            validation_result: ValidationResult ê°ì²´

        Returns:
            ì˜ˆìƒ ì²­í¬ ê°œìˆ˜
        """
        base_count = 2  # í—¤ë”, ê¸°ë³¸ì •ë³´, ì™„ë£Œ (í•­ìƒ ìƒì„±ë˜ëŠ” ì²­í¬ë“¤)

        # ì´ìŠˆ ì²­í¬ë“¤
        if hasattr(validation_result, 'issues') and validation_result.issues:
            base_count += 1  # ì´ìŠˆê°€ ìˆìœ¼ë©´ 1ê°œ ì²­í¬ ì¶”ê°€
            self.logger.debug(f"ì´ìŠˆ ì²­í¬ ì¶”ê°€: {validation_result.issues}")
        else:
            self.logger.debug(
                f"ì´ìŠˆ ì²­í¬ ì¶”ê°€ ì•ˆë¨: hasattr={hasattr(validation_result, 'issues')}, issues={validation_result.issues}"
            )

        # êµ¬ì¡° ì •ë³´ ì²­í¬
        if hasattr(validation_result, 'structure'):
            base_count += 1

        # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²­í¬
        if hasattr(validation_result, 'performance_metrics'):
            base_count += 1

        # í’ˆì§ˆ ë©”íŠ¸ë¦­ ì²­í¬
        if hasattr(validation_result, 'quality_metrics'):
            base_count += 1

        self.logger.debug(
            f"ì²­í¬ ê°œìˆ˜ ê³„ì‚°: ê¸°ë³¸={2}, ì´ìŠˆ={1 if hasattr(validation_result, 'issues') and validation_result.issues else 0}, êµ¬ì¡°={1 if hasattr(validation_result, 'structure') else 0}, ì„±ëŠ¥={1 if hasattr(validation_result, 'performance_metrics') else 0}, í’ˆì§ˆ={1 if hasattr(validation_result, 'quality_metrics') else 0}, ì´ê³„={base_count}"
        )

        return base_count
