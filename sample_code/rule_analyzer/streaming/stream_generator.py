"""
ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸°

ValidationResultë¥¼ ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
"""

import asyncio
import logging
from typing import AsyncGenerator, Optional

from .stream_models import ChunkType, StreamingChunk, StreamingOptions
from .utils.progress_tracker import ProgressTracker


# ìƒëŒ€ importë¥¼ ì ˆëŒ€ importë¡œ ë³€ê²½
try:
    from ..formatters import FormattingOptions, TextFormatter
except ImportError:
    # ìƒëŒ€ importê°€ ì‹¤íŒ¨í•  ê²½ìš° ì ˆëŒ€ import ì‹œë„
    try:
        from formatters import FormattingOptions, TextFormatter
    except ImportError:
        # ëª¨ë“  importê°€ ì‹¤íŒ¨í•  ê²½ìš° ë”ë¯¸ í´ë˜ìŠ¤ ì‚¬ìš©
        class TextFormatter:
            def __init__(self, options=None):
                pass

            def format(self, result):
                return str(result)

        class FormattingOptions:
            def __init__(self):
                pass


class StreamGenerator:
    """
    ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸°

    ValidationResultë¥¼ ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¡œ ë³€í™˜í•˜ì—¬ ì „ì†¡í•©ë‹ˆë‹¤.
    """

    def __init__(self, options: Optional[StreamingOptions] = None):
        """
        ìŠ¤íŠ¸ë¦¬ë° ìƒì„±ê¸° ì´ˆê¸°í™”

        Args:
            options: ìŠ¤íŠ¸ë¦¬ë° ì˜µì…˜
        """
        self.logger = logging.getLogger(__name__)
        self.options = options or StreamingOptions()
        self.progress_tracker = ProgressTracker()

    async def generate_stream(
        self, validation_result, chunk_delay: float = 0.1
    ) -> AsyncGenerator[StreamingChunk, None]:
        """
        ë¶„ì„ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¡œ ìƒì„±

        Args:
            validation_result: ValidationResult ê°ì²´
            chunk_delay: ì²­í¬ ê°„ ì§€ì—° ì‹œê°„ (ì´ˆ)

        Yields:
            StreamingChunk ê°ì²´
        """
        try:
            self.logger.info("ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ìƒì„± ì‹œì‘")

            # 1. í—¤ë” ì²­í¬
            header_chunk = self._create_header_chunk(validation_result)
            yield header_chunk
            await asyncio.sleep(chunk_delay)

            # 2. ê¸°ë³¸ ì •ë³´ ì²­í¬
            basic_chunk = self._create_basic_info_chunk(validation_result)
            yield basic_chunk
            await asyncio.sleep(chunk_delay)

            # 3. ì´ìŠˆ ì •ë³´ ì²­í¬ë“¤
            if hasattr(validation_result, 'issues') and validation_result.issues:
                for i, issue in enumerate(validation_result.issues):
                    issue_chunk = self._create_issue_chunk(issue, i)
                    yield issue_chunk
                    await asyncio.sleep(chunk_delay)

            # 4. êµ¬ì¡° ì •ë³´ ì²­í¬
            if hasattr(validation_result, 'structure'):
                structure_chunk = self._create_structure_chunk(
                    validation_result.structure
                )
                yield structure_chunk
                await asyncio.sleep(chunk_delay)

            # 5. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²­í¬
            if hasattr(validation_result, 'performance_metrics'):
                performance_chunk = self._create_performance_chunk(
                    validation_result.performance_metrics
                )
                yield performance_chunk
                await asyncio.sleep(chunk_delay)

            # 6. í’ˆì§ˆ ë©”íŠ¸ë¦­ ì²­í¬
            if hasattr(validation_result, 'quality_metrics'):
                quality_chunk = self._create_quality_chunk(
                    validation_result.quality_metrics
                )
                yield quality_chunk
                await asyncio.sleep(chunk_delay)

            # 7. ì™„ë£Œ ì²­í¬
            completion_chunk = self._create_completion_chunk(validation_result)
            yield completion_chunk

            self.logger.info("ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° ìƒì„± ì™„ë£Œ")

        except Exception as e:
            self.logger.error(f"ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            error_chunk = self._create_error_chunk(str(e))
            yield error_chunk

    def _create_header_chunk(self, validation_result) -> StreamingChunk:
        """í—¤ë” ì²­í¬ ìƒì„±"""
        # rule_summaryê°€ ì—†ëŠ” ê²½ìš° summary ë˜ëŠ” ê¸°ë³¸ê°’ ì‚¬ìš©
        summary = getattr(validation_result, 'rule_summary', None)
        if not summary:
            summary = getattr(validation_result, 'summary', 'ë¶„ì„ ì™„ë£Œ')

        content = f"ë£° ë¶„ì„ ê²°ê³¼: {summary}"

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=self._get_timestamp(),
            progress=0.0,
            total_chunks=self._get_total_items(validation_result),
            metadata={
                "rule_id": getattr(validation_result, 'rule_id', 'unknown'),
                "analysis_version": getattr(
                    validation_result.report_metadata, 'analysis_version', '1.0.0'
                ),
            },
        )

    def _create_basic_info_chunk(self, validation_result) -> StreamingChunk:
        """ê¸°ë³¸ ì •ë³´ ì²­í¬ ìƒì„±"""
        content = f"""
ğŸ“Š ê¸°ë³¸ ë¶„ì„ ì •ë³´
================
âœ… ìœ íš¨ì„±: {'ìœ íš¨í•¨' if validation_result.is_valid else 'ìœ íš¨í•˜ì§€ ì•ŠìŒ'}
ğŸ“ ìš”ì•½: {validation_result.summary or 'ìš”ì•½ ì—†ìŒ'}
ğŸš¨ ì´ ì´ìŠˆ: {validation_result.get_total_issues()}ê°œ
âš ï¸ ì¹˜ëª…ì  ì´ìŠˆ: {len(validation_result.get_critical_issues())}ê°œ
ğŸ“ˆ ë³µì¡ë„ ì ìˆ˜: {validation_result.complexity_score}/100
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=self._get_timestamp(),
            progress=0.1,
            total_chunks=self._get_total_items(validation_result),
            metadata={
                "is_valid": validation_result.is_valid,
                "total_issues": validation_result.get_total_issues(),
                "critical_issues": len(validation_result.get_critical_issues()),
            },
        )

    def _create_issue_chunk(self, issue, index: int) -> StreamingChunk:
        """ì´ìŠˆ ì •ë³´ ì²­í¬ ìƒì„±"""
        # detected_atê°€ ë¬¸ìì—´ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©, ê°ì²´ì¸ ê²½ìš° isoformat() í˜¸ì¶œ
        detected_at = getattr(issue, 'detected_at', 'N/A')
        if hasattr(detected_at, 'isoformat'):
            detected_at = detected_at.isoformat()

        content = f"""
ğŸš¨ ì´ìŠˆ {index + 1}: {getattr(issue, 'issue_type', 'unknown')}
   ì‹¬ê°ë„: {getattr(issue, 'severity', 'unknown')}
   ì„¤ëª…: {getattr(issue, 'explanation', 'ì„¤ëª… ì—†ìŒ')}
   ì œì•ˆ: {getattr(issue, 'suggestion', 'ì œì•ˆì‚¬í•­ ì—†ìŒ')}
   ë°œê²¬ ì‹œê°„: {detected_at}
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=detected_at,
            progress=0.2 + (index * 0.1),
            total_chunks=self._get_total_items(None),  # ì´ìŠˆ ê°œìˆ˜ëŠ” ë³„ë„ë¡œ ê³„ì‚°
            metadata={
                "issue_type": getattr(issue, 'issue_type', 'unknown'),
                "severity": getattr(issue, 'severity', 'unknown'),
                "index": index,
            },
        )

    def _create_structure_chunk(self, structure) -> StreamingChunk:
        """êµ¬ì¡° ì •ë³´ ì²­í¬ ìƒì„±"""
        content = f"""
ğŸ—ï¸ êµ¬ì¡° ë¶„ì„
============
   ìµœëŒ€ ê¹Šì´: {getattr(structure, 'depth', 'N/A')}
   ì¡°ê±´ ê°œìˆ˜: {getattr(structure, 'condition_count', 'N/A')}
   ì•¡ì…˜ ê°œìˆ˜: {getattr(structure, 'action_count', 'N/A')}
   ë³µì¡ë„ ì ìˆ˜: {getattr(structure, 'complexity_score', 'N/A')}/100
   íŒ¨í„´: {', '.join(getattr(structure, 'detected_patterns', [])) if getattr(structure, 'detected_patterns', []) else 'ì—†ìŒ'}
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=self._get_timestamp(),
            progress=0.7,
            total_chunks=self._get_total_items(None),
            metadata={
                "depth": getattr(structure, 'depth', 'N/A'),
                "complexity_score": getattr(structure, 'complexity_score', 'N/A'),
                "pattern_count": len(getattr(structure, 'detected_patterns', [])),
            },
        )

    def _create_performance_chunk(self, performance) -> StreamingChunk:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì²­í¬ ìƒì„±"""
        # estimated_execution_time_msê°€ ìˆ«ìì¸ì§€ í™•ì¸
        execution_time = getattr(performance, 'estimated_execution_time_ms', 'N/A')
        if execution_time != 'N/A' and execution_time is not None:
            execution_time_str = f"{execution_time:.2f}ms"
        else:
            execution_time_str = "N/A"

        content = f"""
âš¡ ì„±ëŠ¥ ë©”íŠ¸ë¦­
==============
   ì„±ëŠ¥ ì ìˆ˜: {getattr(performance, 'performance_score', 'N/A')}/100
   ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„: {execution_time_str}
   ë³µì¡ë„ ë“±ê¸‰: {getattr(performance, 'complexity_rating', 'N/A')}
   ìµœì í™” ì œì•ˆ: {len(getattr(performance, 'optimization_suggestions', []))}ê°œ
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=self._get_timestamp(),
            progress=0.8,
            total_chunks=self._get_total_items(None),
            metadata={
                "performance_score": getattr(performance, 'performance_score', 'N/A'),
                "execution_time": getattr(
                    performance, 'estimated_execution_time_ms', 'N/A'
                ),
                "optimization_count": len(
                    getattr(performance, 'optimization_suggestions', [])
                ),
            },
        )

    def _create_quality_chunk(self, quality) -> StreamingChunk:
        """í’ˆì§ˆ ë©”íŠ¸ë¦­ ì²­í¬ ìƒì„±"""
        content = f"""
ğŸ¯ í’ˆì§ˆ ë©”íŠ¸ë¦­
==============
   ì „ì²´ ì ìˆ˜: {getattr(quality, 'overall_score', 'N/A')}/100
   í’ˆì§ˆ ë“±ê¸‰: {getattr(quality, 'quality_grade', 'N/A')}
   ìœ ì§€ë³´ìˆ˜ì„±: {getattr(quality, 'maintainability_score', 'N/A')}/100
   ê°€ë…ì„±: {getattr(quality, 'readability_score', 'N/A')}/100
   ì™„ì„±ë„: {getattr(quality, 'completeness_score', 'N/A')}/100
   ì¼ê´€ì„±: {getattr(quality, 'consistency_score', 'N/A')}/100
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_TEXT,
            content=content,
            timestamp=self._get_timestamp(),
            progress=0.9,
            total_chunks=self._get_total_items(None),
            metadata={
                "overall_score": getattr(quality, 'overall_score', 'N/A'),
                "quality_grade": getattr(quality, 'quality_grade', 'N/A'),
                "maintainability": getattr(quality, 'maintainability_score', 'N/A'),
            },
        )

    def _create_completion_chunk(self, validation_result) -> StreamingChunk:
        """ì™„ë£Œ ì²­í¬ ìƒì„±"""
        timestamp = getattr(
            validation_result.report_metadata, 'analysis_timestamp', 'N/A'
        )
        generation_time = getattr(
            validation_result.report_metadata, 'report_generation_time', 'N/A'
        )
        generated_by = getattr(
            validation_result.report_metadata, 'report_generated_by', 'N/A'
        )
        environment = getattr(validation_result.report_metadata, 'environment', 'N/A')

        content = f"""
âœ… ë¶„ì„ ì™„ë£Œ!
============
   ì´ ì†Œìš” ì‹œê°„: {generation_time}ì´ˆ
   ìƒì„±ì: {generated_by}
   í™˜ê²½: {environment}
   ì™„ë£Œ ì‹œê°„: {timestamp}
"""

        return StreamingChunk(
            type=ChunkType.ANALYSIS_COMPLETE,
            content=content,
            timestamp=timestamp,
            progress=1.0,
            total_chunks=self._get_total_items(validation_result),
            metadata={
                "generation_time": generation_time,
                "generated_by": generated_by,
                "status": "completed",
            },
        )

    def _create_error_chunk(self, error_message: str) -> StreamingChunk:
        """ì—ëŸ¬ ì²­í¬ ìƒì„±"""
        return StreamingChunk(
            type=ChunkType.ANALYSIS_ERROR,
            content=f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {error_message}",
            timestamp=self._get_timestamp(),
            progress=1.0,
            total_chunks=1,
            metadata={"error": True, "error_message": error_message, "status": "error"},
        )

    def _get_timestamp(self) -> str:
        """í˜„ì¬ íƒ€ì„ìŠ¤íƒ¬í”„ ë°˜í™˜"""
        from datetime import datetime

        return datetime.now().isoformat()

    def _get_total_items(self, validation_result) -> int:
        """ì´ ì•„ì´í…œ ê°œìˆ˜ ë°˜í™˜"""
        if not validation_result:
            return 1

        base_count = 5  # í—¤ë”, ê¸°ë³¸ì •ë³´, êµ¬ì¡°, ì„±ëŠ¥, í’ˆì§ˆ, ì™„ë£Œ

        if hasattr(validation_result, 'issues') and validation_result.issues:
            base_count += len(validation_result.issues)

        return base_count
