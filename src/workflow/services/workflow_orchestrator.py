"""
ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°
5ê°œ ëª¨ë“ˆì„ ì¡°ìœ¨í•˜ì—¬ ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
"""

import time
from typing import Dict, Any
from .modules import (
    QuestionStandardizer,
    KeywordExtractor, 
    RAGSearcher,
    QualityReviewer,
    ResponseGenerator
)
from .shared import LLMClient, RAGClient
from .shared.models import WorkflowRequest, WorkflowResponse


class WorkflowOrchestrator:
    """ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""
    
    def __init__(self, llm_base_url: str = None, rag_base_url: str = None):
        # í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.llm_client = LLMClient(llm_base_url)
        self.rag_client = RAGClient(rag_base_url)
        
        # ëª¨ë“ˆ ì´ˆê¸°í™”
        self.standardizer = QuestionStandardizer(self.llm_client)
        self.keyword_extractor = KeywordExtractor(self.llm_client)
        self.rag_searcher = RAGSearcher(self.rag_client)
        self.quality_reviewer = QualityReviewer(self.llm_client)
        self.response_generator = ResponseGenerator(self.llm_client)
    
    async def process_workflow(self, request: WorkflowRequest, status_callback=None) -> WorkflowResponse:
        """
        ìµœì í™”ëœ 5ë‹¨ê³„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
        
        1. ì‚¬ìš©ì ì§ˆë¬¸ì„ LLMì´ ìš©ì–´ì§‘ ê¸°ë°˜ìœ¼ë¡œ í‘œì¤€í™”
        2. í‘œì¤€í™”ëœ ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        3. í‘œì¤€í™”ëœ ì§ˆë¬¸+í‚¤ì›Œë“œë¡œ RAG ê²€ìƒ‰ (ì†ŒìŠ¤ê²€ìƒ‰+ë…ìŠ¤íŠ¸ë§ê²€ìƒ‰+MDê²€ìƒ‰)
        4. ê²€ìƒ‰ëœ RAG ê²°ê³¼ê°€ ì˜ëœê±´ì§€ LLM ê²€í†  ë° í’ˆì§ˆ ê°œì„ 
        5. ê°œì„ ëœ RAG ë°ì´í„°ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
        
        Args:
            request: ì›Œí¬í”Œë¡œìš° ìš”ì²­
            
        Returns:
            ì›Œí¬í”Œë¡œìš° ì‘ë‹µ
        """
        start_time = time.time()
        
        try:
            print(f"ğŸš€ ìµœì í™”ëœ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            print(f"   ì›ë³¸ ì§ˆë¬¸: {request.query}")
            print(f"   ëª¨ë¸: {request.model}")
            print(f"   RAG ì‚¬ìš©: {request.use_rag}")
            
            # 1ë‹¨ê³„: ì§ˆë¬¸ í‘œì¤€í™”
            if status_callback:
                await status_callback("Step 1: Question standardization in progress...", "1")
            step1_start = time.time()
            standardization_result = await self.standardizer.standardize(
                request.query, request.model
            )
            step1_time = time.time() - step1_start
            
            if not standardization_result["success"]:
                return WorkflowResponse(
                    success=False,
                    response="ì§ˆë¬¸ í‘œì¤€í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    original_query=request.query,
                    model_used=request.model,
                    processing_time=time.time() - start_time,
                    error=standardization_result.get("error")
                )
            
            standardized_query = standardization_result["standardized_query"]
            print(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ [â±ï¸ {step1_time:.2f}ì´ˆ]")
            
            # 2ë‹¨ê³„: í‚¤ì›Œë“œ ì¶”ì¶œ
            if status_callback:
                await status_callback("Step 2: Keyword extraction in progress...", "2")
            step2_start = time.time()
            keyword_result = await self.keyword_extractor.extract(
                standardized_query, request.model
            )
            step2_time = time.time() - step2_start
            
            if not keyword_result["success"]:
                keywords = []
            else:
                keywords = keyword_result["keywords"]
            
            print(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ [â±ï¸ {step2_time:.2f}ì´ˆ]")
            
            # 3ë‹¨ê³„: RAG ê²€ìƒ‰
            if status_callback:
                await status_callback("Step 3: RAG search in progress...", "3")
            step3_start = time.time()
            if request.use_rag:
                search_result = await self.rag_searcher.search(
                    standardized_query, keywords, limit=10
                )
                search_results = search_result.get("results", [])
            else:
                search_results = []
            step3_time = time.time() - step3_start
            
            print(f"âœ… 3ë‹¨ê³„ ì™„ë£Œ [â±ï¸ {step3_time:.2f}ì´ˆ] - {len(search_results)}ê°œ ê²°ê³¼")
            
            # 4ë‹¨ê³„: í’ˆì§ˆ ê²€í† 
            if status_callback:
                await status_callback("Step 4: Quality review in progress...", "4")
            step4_start = time.time()
            if search_results:
                quality_result = await self.quality_reviewer.review(
                    search_results, request.query, request.model
                )
                reviewed_results = quality_result.get("reviewed_results", search_results)
                quality_score = quality_result.get("quality_score", 0.0)
            else:
                reviewed_results = []
                quality_score = 0.0
            step4_time = time.time() - step4_start
            
            print(f"âœ… 4ë‹¨ê³„ ì™„ë£Œ [â±ï¸ {step4_time:.2f}ì´ˆ] - í’ˆì§ˆ ì ìˆ˜: {quality_score:.2f}")
            
            # 5ë‹¨ê³„: ì‘ë‹µ ìƒì„±
            if status_callback:
                await status_callback("Step 5: Final response generation in progress...", "5")
            step5_start = time.time()
            response_result = await self.response_generator.generate(
                request.query, reviewed_results, request.model
            )
            step5_time = time.time() - step5_start
            
            if not response_result["success"]:
                return WorkflowResponse(
                    success=False,
                    response="ì‘ë‹µ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
                    original_query=request.query,
                    standardized_query=standardized_query,
                    keywords=keywords,
                    search_results_count=len(search_results),
                    quality_score=quality_score,
                    model_used=request.model,
                    processing_time=time.time() - start_time,
                    error=response_result.get("error")
                )
            
            final_response = response_result["response"]
            print(f"âœ… 5ë‹¨ê³„ ì™„ë£Œ [â±ï¸ {step5_time:.2f}ì´ˆ]")
            
            # ì „ì²´ ì²˜ë¦¬ ì‹œê°„
            total_time = time.time() - start_time
            
            print(f"ğŸ¯ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ [â±ï¸ ì´ {total_time:.2f}ì´ˆ]")
            print(f"   ë‹¨ê³„ë³„ ì‹œê°„:")
            print(f"     1. í‘œì¤€í™”: {step1_time:.2f}ì´ˆ ({step1_time/total_time*100:.1f}%)")
            print(f"     2. í‚¤ì›Œë“œ: {step2_time:.2f}ì´ˆ ({step2_time/total_time*100:.1f}%)")
            print(f"     3. ê²€ìƒ‰: {step3_time:.2f}ì´ˆ ({step3_time/total_time*100:.1f}%)")
            print(f"     4. ê²€í† : {step4_time:.2f}ì´ˆ ({step4_time/total_time*100:.1f}%)")
            print(f"     5. ì‘ë‹µ: {step5_time:.2f}ì´ˆ ({step5_time/total_time*100:.1f}%)")
            
            return WorkflowResponse(
                success=True,
                response=final_response,
                original_query=request.query,
                standardized_query=standardized_query,
                keywords=keywords,
                search_results_count=len(search_results),
                quality_score=quality_score,
                model_used=request.model,
                processing_time=total_time
            )
            
        except Exception as e:
            print(f"âŒ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return WorkflowResponse(
                success=False,
                response="ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                original_query=request.query,
                model_used=request.model,
                processing_time=time.time() - start_time,
                error=str(e)
            )
