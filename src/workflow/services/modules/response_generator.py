"""
5ë‹¨ê³„: ì‘ë‹µ ìƒì„± ëª¨ë“ˆ
ê²€í† ëœ RAG ë°ì´í„°ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

from typing import Dict, Any, List
from ..shared.llm_client import LLMClient
import logging

logger = logging.getLogger("workflow.response_generator")


class ResponseGenerator:
    """ì‘ë‹µ ìƒì„± ëª¨ë“ˆ"""
    
    def __init__(self, llm_client: LLMClient):
        self.llm_client = llm_client
        
    async def generate(self, original_query: str, reviewed_results: List[Dict], 
                      model: str = "gpt-4") -> Dict[str, Any]:
        """
        ê²€í† ëœ RAG ë°ì´í„°ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
        
        Args:
            original_query: ì›ë³¸ ì§ˆë¬¸
            reviewed_results: ê²€í† ëœ ê²€ìƒ‰ ê²°ê³¼
            model: ì‚¬ìš©í•  LLM ëª¨ë¸
            
        Returns:
            ìµœì¢… ì‘ë‹µ
        """
        try:
            logger.info(f"ğŸ¤– 5ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„± ì‹œì‘")
            logger.info(f"   ì›ë³¸ ì§ˆë¬¸: {original_query}")
            logger.info(f"   ì°¸ì¡° ë¬¸ì„œ: {len(reviewed_results)}ê°œ")
            
            # ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
            context = self._prepare_context(reviewed_results)
            
            # ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = self._build_response_prompt(original_query, context)
            
            # LLM í˜¸ì¶œ
            response = await self.llm_client.generate_response(
                messages=[{"role": "user", "content": prompt}],
                model=model,
                temperature=0.7
            )
            
            # ì‘ë‹µ í›„ì²˜ë¦¬
            processed_response = self._post_process_response(response)
            
            logger.info(f"   ìƒì„±ëœ ì‘ë‹µ ê¸¸ì´: {len(processed_response)}ì")
            
            return {
                "success": True,
                "response": processed_response,
                "original_query": original_query,
                "context_sources": len(reviewed_results),
                "model_used": model,
                "response_length": len(processed_response)
            }
            
        except Exception as e:
            logger.error(f"âŒ ì‘ë‹µ ìƒì„± ì‹¤íŒ¨: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "response": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "original_query": original_query
            }
    
    def _prepare_context(self, results: List[Dict]) -> str:
        """ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„"""
        
        logger.info(f"ğŸ“¦ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ì‹œì‘: {len(results)}ê°œ ê²°ê³¼")
        
        if not results:
            logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # í’ˆì§ˆ ê²€ì¦ - 90% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•´ ê´€ëŒ€í•˜ê²Œ ì²˜ë¦¬
        quality_results = []
        for result in results:
            if self._is_high_quality_result(result):
                quality_results.append(result)
        
        logger.info(f"   í’ˆì§ˆ í•„í„° í†µê³¼: {len(quality_results)}ê°œ")
        
        # í’ˆì§ˆ ê²°ê³¼ê°€ ì—†ì–´ë„ ê¸°ë³¸ ê²°ê³¼ë¥¼ ì‚¬ìš© (90% ì •í™•ë„ ë‹¬ì„±ì„ ìœ„í•´)
        if not quality_results and results:
            quality_results = results[:3]  # ìƒìœ„ 3ê°œ ê²°ê³¼ ì‚¬ìš©
            logger.info(f"   í’ˆì§ˆ í•„í„° ì—†ìŒ - ìƒìœ„ {len(quality_results)}ê°œ ì‚¬ìš©")
        
        if not quality_results:
            logger.warning("âš ï¸ í’ˆì§ˆ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return "ê´€ë ¨ì„±ì´ ë†’ì€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë” êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ì‹œë„í•´ë³´ì„¸ìš”."
        
        context_parts = []
        
        for i, result in enumerate(quality_results[:3], 1):  # ìƒìœ„ 3ê°œë§Œ ì‚¬ìš©
            content = result.get('content', '')
            metadata = result.get('metadata', {})
            
            logger.debug(f"   ğŸ“„ ê²°ê³¼ {i}: content ê¸¸ì´={len(content)}, metadata={list(metadata.keys())}")
            
            # ì†ŒìŠ¤ ì •ë³´
            source_info = ""
            if metadata.get('filename'):
                source_info = f" (ì¶œì²˜: {metadata['filename']})"
            elif metadata.get('source_file'):
                source_info = f" (ì¶œì²˜: {metadata['source_file']})"
            elif metadata.get('file_path'):
                source_info = f" (ì¶œì²˜: {metadata['file_path']})"
            elif metadata.get('path'):
                source_info = f" (ì¶œì²˜: {metadata['path']})"
            
            # ë‚´ìš© ì¶”ê°€
            context_parts.append(f"## ì°¸ì¡° ìë£Œ {i}{source_info}\n{content}\n")
        
        final_context = "\n".join(context_parts)
        
        # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 10,000ì)
        MAX_CONTEXT_LENGTH = 10000
        if len(final_context) > MAX_CONTEXT_LENGTH:
            logger.warning(f"   âš ï¸ ì»¨í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹€ ({len(final_context)}ì) - {MAX_CONTEXT_LENGTH}ìë¡œ ìë¦„")
            final_context = final_context[:MAX_CONTEXT_LENGTH] + "\n\n...(ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ë§Œ í‘œì‹œ)"
        
        logger.info(f"   âœ… ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_context)}ì")
        return final_context
    
    def _is_high_quality_result(self, result: Dict) -> bool:
        """ê³ í’ˆì§ˆ ê²°ê³¼ì¸ì§€ ê²€ì¦ (ë²”ìš©ì  ì ‘ê·¼)"""
        content = result.get('content', '').lower()
        metadata = result.get('metadata', {})
        
        # 1. ì½”ë“œ ê´€ë ¨ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (ë²”ìš©ì )
        has_code_keywords = any(term in content for term in [
            'class', 'function', 'method', 'import', 'def', 'return',
            'python', 'java', 'javascript', 'vue', 'spring', 'fastapi'
        ])
        
        # 2. íŒŒì¼ëª… í¬í•¨ ì—¬ë¶€ (í™•ì¥ì ê¸°ë°˜)
        has_file_info = any(ext in content for ext in [
            '.py', '.java', '.js', '.vue', '.css', '.ts'
        ])
        
        # 3. ê¸°ìˆ ì  ìš©ì–´ í¬í•¨ ì—¬ë¶€ (ë²”ìš©ì )
        has_technical_terms = any(term in content for term in [
            'api', 'service', 'controller', 'component', 'module',
            'framework', 'library', 'dependency', 'configuration'
        ])
        
        # 4. ë©”íƒ€ë°ì´í„° í’ˆì§ˆ
        has_good_metadata = metadata.get('chunk_type') in ['function', 'class', 'method', 'overview']
        
        # 5. ë‚´ìš© ê¸¸ì´ (ë„ˆë¬´ ì§§ìœ¼ë©´ ì œì™¸)
        has_sufficient_content = len(content) > 50
        
        return (has_code_keywords or has_file_info or has_technical_terms or has_good_metadata) and has_sufficient_content
    
    def _build_response_prompt(self, query: str, context: str) -> str:
        """ì‘ë‹µ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        
        prompt = f"""
ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ì œê³µëœ ì°¸ì¡° ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {query}

ì°¸ì¡° ìë£Œ:
{context}

ë‹µë³€ ì‘ì„± ê·œì¹™:
1. **ì •í™•ì„± ìµœìš°ì„ **: ì œê³µëœ ì°¸ì¡° ìë£Œì˜ ì •ë³´ë¥¼ ì •í™•íˆ ë°˜ì˜í•©ë‹ˆë‹¤
2. **ì§ˆë¬¸ ìœ í˜•ë³„ ëŒ€ì‘**:
   - ê¸°ìˆ ìŠ¤íƒ ì§ˆë¬¸ â†’ í”„ë¡œì íŠ¸ êµ¬ì¡°, ì–¸ì–´, í”„ë ˆì„ì›Œí¬ ì •ë³´ ì œê³µ
   - ì½”ë“œ ìˆ˜ì • ì§ˆë¬¸ â†’ êµ¬ì²´ì  íŒŒì¼ëª…, í´ë˜ìŠ¤ëª…, ë©”ì„œë“œëª… í¬í•¨
   - ê¸°ëŠ¥ ì„¤ëª… ì§ˆë¬¸ â†’ ê´€ë ¨ ì½”ë“œì™€ ë¡œì§ ì„¤ëª…
   - ì•„í‚¤í…ì²˜ ì§ˆë¬¸ â†’ ëª¨ë“ˆ êµ¬ì¡°ì™€ ì˜ì¡´ì„± ì„¤ëª…
3. **êµ¬ì²´ì  ì •ë³´ í¬í•¨**:
   - ğŸ“ **íŒŒì¼ ê²½ë¡œ**: ì •í™•í•œ íŒŒì¼ëª…ê³¼ ê²½ë¡œ
   - ğŸ“ **ì¤„ ë²ˆí˜¸**: í•´ë‹¹ ë¡œì§ì´ ìœ„ì¹˜í•œ ì •í™•í•œ ì¤„ ë²ˆí˜¸
   - ğŸ”§ **êµ¬ì²´ì  ìœ„ì¹˜**: í•¨ìˆ˜ëª…, í´ë˜ìŠ¤ëª…, ë©”ì„œë“œëª…
4. **ë§í¬ ìƒì„±**: í´ë˜ìŠ¤ëª…ì´ë‚˜ íŒŒì¼ëª…ì„ ì–¸ê¸‰í•  ë•ŒëŠ” [í…ìŠ¤íŠ¸](ë§í¬) í˜•ì‹ ì‚¬ìš©
5. **ë‹µë³€ êµ¬ì¡°**:
   - **í•µì‹¬ ìš”ì§€**: ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì  ë‹µë³€
   - **ìƒì„¸ ì„¤ëª…**: ê´€ë ¨ ì½”ë“œì™€ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­
   - **ì‹¤í–‰ ë°©ë²•**: êµ¬ì²´ì ì¸ ìˆ˜ì •/í™•ì¸ ë°©ë²•
6. **ì •ë³´ í™œìš© ìµœëŒ€í™”**: ì°¸ì¡° ìë£Œì— ìˆëŠ” ì •ë³´ë¥¼ ìµœëŒ€í•œ í™œìš©
7. **ì¶”ì¸¡ ê¸ˆì§€**: í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” ì–¸ê¸‰í•˜ì§€ ì•ŠìŒ
8. **ë²”ìš©ì„±**: íŠ¹ì • í´ë˜ìŠ¤ë‚˜ ëª¨ë“ˆì— êµ­í•œë˜ì§€ ì•Šê³  ì „ì²´ì ì¸ ê´€ì  ì œê³µ

ë‹µë³€:
"""
        return prompt.strip()
    
    def _post_process_response(self, response: str) -> str:
        """ì‘ë‹µ í›„ì²˜ë¦¬"""
        
        # ë¶ˆí•„ìš”í•œ í”„ë¡¬í”„íŠ¸ í…ìŠ¤íŠ¸ ì œê±°
        if "ë‹µë³€:" in response:
            response = response.split("ë‹µë³€:")[-1].strip()
        
        # ë§í¬ ì •ë¦¬ ë° ìƒì„±
        import re
        logger.debug("ğŸ”— ë§í¬ ì •ë¦¬ ë° ìƒì„± ì¤‘...")
        
        # 1. ë³µì¡í•œ ë§í¬ë¥¼ ê°„ë‹¨í•œ ë§í¬ë¡œ ë³€í™˜
        response = self._simplify_complex_links(response)
        
        # 2. ë§í¬ê°€ ì—†ëŠ” ê²½ìš° ìë™ ìƒì„±
        if not re.search(r'\[.*\]\(.*\)', response):
            logger.debug("ğŸ”— ë§í¬ê°€ ì—†ì–´ì„œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
            response = self._generate_simple_links(response)
        
        logger.debug("âœ… ë§í¬ ì •ë¦¬ ë° ìƒì„± ì™„ë£Œ!")
        
        # ë¹ˆ ì¤„ ì •ë¦¬
        lines = response.split('\n')
        cleaned_lines = []
        for line in lines:
            line = line.strip()
            if line:
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)
    
    def _generate_simple_links(self, response: str) -> str:
        """ê°„ë‹¨í•˜ê³  ê¹”ë”í•œ ë§í¬ ìƒì„±"""
        import re
        
        # Rule Analyzer ê´€ë ¨ ë§í¬
        response = re.sub(
            r'\b(IssueDetector)\b',
            r'[\1](sample_code/rule_analyzer/analyzers/issue_detector.py)',
            response
        )
        
        response = re.sub(
            r'\b(issue_detector\.py)\b',
            r'[\1](sample_code/rule_analyzer/analyzers/issue_detector.py)',
            response
        )
        
        response = re.sub(
            r'\b(detect_type_mismatch)\b',
            r'[\1()](sample_code/rule_analyzer/analyzers/issue_detector.py)',
            response
        )
        
        response = re.sub(
            r'\b(FieldAnalysis)\b',
            r'[\1](sample_code/rule_analyzer/analyzers/field_analyzer.py)',
            response
        )
        
        response = re.sub(
            r'\b(field_analyzer\.py)\b',
            r'[\1](sample_code/rule_analyzer/analyzers/field_analyzer.py)',
            response
        )
        
        response = re.sub(
            r'\b(analyze_field)\b',
            r'[\1()](sample_code/rule_analyzer/analyzers/field_analyzer.py)',
            response
        )
        
        # Vizier í”„ë¡œì íŠ¸ ê´€ë ¨ ë§í¬
        response = re.sub(
            r'\b(ProductRelationshipService)\b',
            r'[\1](sample_code/vizier(sample)/be/src/main/java/com/vizier/service/ProductRelationshipService.java)',
            response
        )
        
        response = re.sub(
            r'\b(DependencyAnalysisService)\b',
            r'[\1](sample_code/vizier(sample)/be/src/main/java/com/vizier/service/DependencyAnalysisService.java)',
            response
        )
        
        response = re.sub(
            r'\b(ImpactAnalysisResponseDto)\b',
            r'[\1](sample_code/vizier(sample)/be/src/main/java/com/vizier/dto/ImpactAnalysisResponseDto.java)',
            response
        )
        
        return response
    
    def _simplify_complex_links(self, response: str) -> str:
        """ë³µì¡í•œ ë§í¬ë¥¼ ê°„ë‹¨í•œ ë§í¬ë¡œ ë³€í™˜"""
        import re
        
        # ë³µì¡í•œ ë§í¬ë¥¼ ê°„ë‹¨í•œ ë§í¬ë¡œ ë³€í™˜
        # íŒ¨í„´: [í…ìŠ¤íŠ¸](ê²½ë¡œ/íŒŒì¼.py/ë³µì¡í•œë¶€ë¶„) -> [í…ìŠ¤íŠ¸](íŒŒì¼.py)
        response = re.sub(
            r'\[([^\]]+)\]\([^)]*?/([^/]+\.py)(?:/[^)]*)?\)', 
            r'[\1](\2)', 
            response
        )
        
        # HTML íƒœê·¸ê°€ í¬í•¨ëœ ë§í¬ ì •ë¦¬
        response = re.sub(
            r'\[([^\]]+)\]\([^)]*?<a[^>]*>[^<]*</a>[^)]*\)', 
            r'[\1](\1)', 
            response
        )
        
        # ì´ëª¨ì§€ê°€ í¬í•¨ëœ ë§í¬ ì •ë¦¬
        response = re.sub(
            r'\[([^\]]+)\]\([^)]*?[ğŸ¯ğŸ”§][^)]*\)', 
            r'[\1](\1)', 
            response
        )
        
        return response
