"""
AST íŒŒì‹± ê¸°ë°˜ Python ì½”ë“œ Chunk ìƒì„±ê¸°

íŒŒì¼ ë‹¨ìœ„ ëŒ€ì‹  í•¨ìˆ˜/í´ë˜ìŠ¤/ë©”ì„œë“œ ë‹¨ìœ„ë¡œ ì½”ë“œë¥¼ ë¶„í• í•˜ì—¬
ë” ì •í™•í•œ RAG ê²€ìƒ‰ê³¼ LLM ì²˜ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
"""

import ast
import os
import re
import hashlib
import tiktoken
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path


@dataclass
class CodeChunk:
    """ì½”ë“œ chunkë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    
    # ê¸°ë³¸ ì‹ë³„ ì •ë³´
    chunk_id: str
    file_path: str
    chunk_type: str  # function, method, class, overview
    name: str
    
    # ì½”ë“œ ìœ„ì¹˜ ì •ë³´
    line_range: str  # "12-87"
    content: str     # ì‹¤ì œ ì½”ë“œ ë‚´ìš©
    
    # ë©”íƒ€ë°ì´í„°
    parent: Optional[str] = None  # í´ë˜ìŠ¤ ë‚´ ë©”ì„œë“œì˜ ê²½ìš° í´ë˜ìŠ¤ëª…
    base_classes: List[str] = None
    decorators: List[str] = None
    tags: List[str] = None
    complexity: Optional[int] = None
    docstring: Optional[str] = None
    dependencies: List[str] = None
    is_async: bool = False
    is_generator: bool = False
    token_count: Optional[int] = None
    
    # ì¶”ê°€ ë©”íƒ€ (ì‹œê·¸ë‹ˆì²˜/ì…ì¶œë ¥/ì˜ˆì™¸/í˜¸ì¶œ/ë°ì´í„°í”Œë¡œìš°)
    signature: Optional[str] = None
    parameters: Optional[List[str]] = None
    returns: Optional[str] = None
    raises: Optional[List[str]] = None
    calls: Optional[List[str]] = None
    data_flow_summary: Optional[List[Dict[str, str]]] = None  # [{op, src, dst, line}]
    data_flow_stats: Optional[Dict[str, int]] = None
    code_hash: Optional[str] = None
    
    def __post_init__(self):
        if self.base_classes is None:
            self.base_classes = []
        if self.decorators is None:
            self.decorators = []
        if self.tags is None:
            self.tags = []
        if self.dependencies is None:
            self.dependencies = []
        if self.parameters is None:
            self.parameters = []
        if self.raises is None:
            self.raises = []
        if self.calls is None:
            self.calls = []
        if self.data_flow_summary is None:
            self.data_flow_summary = []
        if self.data_flow_stats is None:
            self.data_flow_stats = {}


class ASTChunker:
    """AST íŒŒì‹± ê¸°ë°˜ ì½”ë“œ chunker"""
    
    def __init__(self, max_tokens: int = 600):
        """
        Args:
            max_tokens: chunkë‹¹ ìµœëŒ€ í† í° ìˆ˜ (sub-chunk ë¶„ë¦¬ ê¸°ì¤€)
        """
        self.max_tokens = max_tokens
        self.encoding = tiktoken.get_encoding("cl100k_base")  # GPT-4 ê¸°ì¤€
        
    def chunk_file(self, file_path: str) -> List[CodeChunk]:
        """
        Python íŒŒì¼ì„ AST íŒŒì‹±í•˜ì—¬ chunk ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        
        Args:
            file_path: ë¶„ì„í•  Python íŒŒì¼ ê²½ë¡œ
            
        Returns:
            CodeChunk ë¦¬ìŠ¤íŠ¸ (overview + functions/classes/methods)
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
                
            # AST íŒŒì‹±
            tree = ast.parse(source_code, filename=file_path)
            
            chunks = []
            
            # 1. Overview chunk ìƒì„± (íŒŒì¼ ìš”ì•½)
            overview_chunk = self._create_overview_chunk(file_path, source_code, tree)
            chunks.append(overview_chunk)
            
            # 2. í´ë˜ìŠ¤ ë° í•¨ìˆ˜ chunk ìƒì„± (ì¤‘ì²© ë°©ì§€)
            processed_nodes = set()
            
            for node in tree.body:  # ìµœìƒìœ„ ë…¸ë“œë§Œ ì²˜ë¦¬
                if isinstance(node, ast.FunctionDef):
                    chunk = self._create_function_chunk(file_path, source_code, node)
                    chunks.append(chunk)
                    processed_nodes.add(id(node))
                    
                elif isinstance(node, ast.AsyncFunctionDef):
                    chunk = self._create_function_chunk(file_path, source_code, node, is_async=True)
                    chunks.append(chunk)
                    processed_nodes.add(id(node))
                    
                elif isinstance(node, ast.ClassDef):
                    # í´ë˜ìŠ¤ ìì²´ chunk
                    class_chunk = self._create_class_chunk(file_path, source_code, node)
                    chunks.append(class_chunk)
                    processed_nodes.add(id(node))
                    
                    # í´ë˜ìŠ¤ ë‚´ ë©”ì„œë“œë“¤
                    for item in node.body:
                        if isinstance(item, ast.FunctionDef):
                            method_chunk = self._create_method_chunk(
                                file_path, source_code, item, node.name
                            )
                            chunks.append(method_chunk)
                            processed_nodes.add(id(item))
                        elif isinstance(item, ast.AsyncFunctionDef):
                            method_chunk = self._create_method_chunk(
                                file_path, source_code, item, node.name, is_async=True
                            )
                            chunks.append(method_chunk)
                            processed_nodes.add(id(item))
            
            # 3. í° chunk ë¶„ë¦¬ (sub-chunking)
            final_chunks = []
            for chunk in chunks:
                if chunk.token_count and chunk.token_count > self.max_tokens:
                    sub_chunks = self._split_large_chunk(chunk)
                    final_chunks.extend(sub_chunks)
                else:
                    final_chunks.append(chunk)
                    
            return final_chunks
            
        except Exception as e:
            print(f"âŒ íŒŒì¼ {file_path} chunk ìƒì„± ì˜¤ë¥˜: {e}")
            return []
    
    def _create_overview_chunk(self, file_path: str, source_code: str, tree: ast.AST) -> CodeChunk:
        """íŒŒì¼ overview chunk ìƒì„±"""
        
        # íŒŒì¼ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        file_name = os.path.basename(file_path)
        
        # ìµœìƒìœ„ docstring ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)
        source_lines = source_code.split('\n')
        docstring = self._extract_docstring(tree, source_lines, 0) or ""
        
        # í´ë˜ìŠ¤ì™€ í•¨ìˆ˜ ì´ë¦„ ëª©ë¡ (ìµœìƒìœ„ë§Œ)
        classes = []
        functions = []
        for node in tree.body:
            if isinstance(node, ast.ClassDef):
                classes.append(node.name)
            elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                functions.append(node.name)
        
        # import ì •ë³´ ì¶”ì¶œ
        imports = self._extract_imports(tree)
        
        # overview ë‚´ìš© êµ¬ì„±
        overview_content = self._generate_overview_content(
            file_name, docstring, classes, functions, imports
        )
        
        # tags ìƒì„±
        tags = self._generate_tags_from_file(file_path, imports, classes, functions)
        
        chunk_id = self._generate_chunk_id(file_path, "overview", "file_overview")
        
        return CodeChunk(
            chunk_id=chunk_id,
            file_path=file_path,
            chunk_type="overview",
            name="file_overview",
            line_range="1-end",
            content=overview_content,
            tags=tags,
            dependencies=imports,
            token_count=len(self.encoding.encode(overview_content))
        )
    
    def _create_function_chunk(self, file_path: str, source_code: str, 
                             node: ast.FunctionDef, is_async: bool = False) -> CodeChunk:
        """í•¨ìˆ˜ chunk ìƒì„±"""
        
        lines = source_code.split('\n')
        
        # í•¨ìˆ˜ ì½”ë“œ ì¶”ì¶œ
        start_line = node.lineno - 1  # 0-based index
        end_line = node.end_lineno if hasattr(node, 'end_lineno') else start_line + 10
        
        function_code = '\n'.join(lines[start_line:end_line])
        
        # docstring ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)
        docstring = self._extract_docstring(node, lines, start_line) or ""
        
        # ë°ì½”ë ˆì´í„° ì¶”ì¶œ
        decorators = [self._get_decorator_name(dec) for dec in node.decorator_list]
        
        # generator ì²´í¬
        is_generator = self._is_generator_function(node)
        
        # ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ ì‚¬ì´í´ë¡œë§¤í‹± ë³µì¡ë„)
        complexity = self._calculate_complexity(node)
        
        # ì‹œê·¸ë‹ˆì²˜/íŒŒë¼ë¯¸í„°/ë¦¬í„´/ì˜ˆì™¸/í˜¸ì¶œ/ë°ì´í„°í”Œë¡œìš° ì¶”ì¶œ
        signature = self._build_signature(node)
        parameters = self._extract_parameters(node)
        returns = self._annotation_to_str(node.returns) if hasattr(node, 'returns') else None
        raises = self._extract_raises(node)
        calls = self._extract_calls(node)
        dflow, dstats = self._extract_data_flow(node)
        
        # tags ìƒì„±
        tags = self._generate_tags_from_function(node, decorators, is_async, is_generator)
        
        chunk_id = self._generate_chunk_id(file_path, "function", node.name)
        
        # ì½”ë“œ í•´ì‹œ
        code_hash = hashlib.sha256(function_code.encode('utf-8')).hexdigest()[:16]

        return CodeChunk(
            chunk_id=chunk_id,
            file_path=file_path,
            chunk_type="async_function" if is_async else "function",
            name=node.name,
            line_range=f"{node.lineno}-{end_line}",
            content=function_code,
            decorators=decorators,
            tags=tags,
            complexity=complexity,
            docstring=docstring,
            is_async=is_async,
            is_generator=is_generator,
            token_count=len(self.encoding.encode(function_code)),
            signature=signature,
            parameters=parameters,
            returns=returns,
            raises=raises,
            calls=calls,
            data_flow_summary=dflow,
            data_flow_stats=dstats,
            code_hash=code_hash
        )
    
    def _create_method_chunk(self, file_path: str, source_code: str, 
                           node: ast.FunctionDef, class_name: str, 
                           is_async: bool = False) -> CodeChunk:
        """í´ë˜ìŠ¤ ë©”ì„œë“œ chunk ìƒì„±"""
        
        # ê¸°ë³¸ì ìœ¼ë¡œ functionê³¼ ë™ì¼í•˜ì§€ë§Œ parent ì •ë³´ ì¶”ê°€
        chunk = self._create_function_chunk(file_path, source_code, node, is_async)
        
        # ë©”ì„œë“œ íŠ¹ì„± ë°˜ì˜
        chunk.chunk_type = "method"
        chunk.parent = class_name
        
        # method tags ì¶”ê°€
        method_tags = []
        if node.name.startswith('__') and node.name.endswith('__'):
            method_tags.append("magic_method")
        elif node.name.startswith('_'):
            method_tags.append("private_method")
        else:
            method_tags.append("public_method")
        
        chunk.tags.extend(method_tags)
        
        # chunk_id ê°±ì‹ 
        chunk.chunk_id = self._generate_chunk_id(file_path, "method", f"{class_name}.{node.name}")
        
        return chunk
    
    def _create_class_chunk(self, file_path: str, source_code: str, node: ast.ClassDef) -> CodeChunk:
        """í´ë˜ìŠ¤ chunk ìƒì„±"""
        
        lines = source_code.split('\n')
        
        # í´ë˜ìŠ¤ í—¤ë” ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë©”ì„œë“œ ì œì™¸)
        start_line = node.lineno - 1
        
        # í´ë˜ìŠ¤ docstringê¹Œì§€ë§Œ í¬í•¨
        class_header_lines = []
        in_class_def = False
        
        for i, line in enumerate(lines[start_line:], start_line):
            class_header_lines.append(line)
            
            # ì²« ë²ˆì§¸ ë©”ì„œë“œë‚˜ ë‹¤ë¥¸ ì •ì˜ë¥¼ ë§Œë‚˜ë©´ ì¤‘ë‹¨
            if in_class_def and (line.strip().startswith('def ') or 
                               line.strip().startswith('async def ') or
                               line.strip().startswith('class ')):
                break
                
            if line.strip().startswith(f'class {node.name}'):
                in_class_def = True
        
        class_code = '\n'.join(class_header_lines)
        
        # ìƒì† í´ë˜ìŠ¤ ì¶”ì¶œ
        base_classes = [self._get_base_class_name(base) for base in node.bases]
        
        # docstring ì¶”ì¶œ (ê°œì„ ëœ ë°©ì‹)
        docstring = self._extract_docstring(node, lines, start_line) or ""
        
        # ë°ì½”ë ˆì´í„° ì¶”ì¶œ
        decorators = [self._get_decorator_name(dec) for dec in node.decorator_list]
        
        # tags ìƒì„±
        tags = self._generate_tags_from_class(node, base_classes, decorators)
        
        chunk_id = self._generate_chunk_id(file_path, "class", node.name)
        
        return CodeChunk(
            chunk_id=chunk_id,
            file_path=file_path,
            chunk_type="class",
            name=node.name,
            line_range=f"{node.lineno}-{node.lineno + 10}",  # í´ë˜ìŠ¤ í—¤ë” ë¶€ë¶„ë§Œ
            content=class_code,
            base_classes=base_classes,
            decorators=decorators,
            tags=tags,
            docstring=docstring,
            token_count=len(self.encoding.encode(class_code)),
            signature=f"class {node.name}({', '.join(base_classes)})" if base_classes else f"class {node.name}"
        )
    
    def _split_large_chunk(self, chunk: CodeChunk) -> List[CodeChunk]:
        """í° chunkë¥¼ sub-chunkë¡œ ë¶„ë¦¬"""
        
        # ê·¹ë‹¨ì ìœ¼ë¡œ í° ê²½ìš°(2000 í† í°+)ë§Œ ë¶„ë¦¬
        if chunk.token_count < 2000:
            return [chunk]
        
        # ì½”ë“œë¥¼ ë…¼ë¦¬ì  ë¸”ë¡ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        lines = chunk.content.split('\n')
        sub_chunks = []
        current_block = []
        current_tokens = 0
        block_count = 0
        
        for line in lines:
            line_tokens = len(self.encoding.encode(line))
            
            # ë¸”ë¡ ê²½ê³„ ì²´í¬ (if, for, while, try, def ë“±)
            is_block_start = any(line.strip().startswith(keyword) for keyword in 
                               ['if ', 'for ', 'while ', 'try:', 'def ', 'class ', 'with '])
            
            # í˜„ì¬ ë¸”ë¡ì´ ë„ˆë¬´ í¬ê³  ìƒˆ ë¸”ë¡ì´ ì‹œì‘ë˜ë©´ ë¶„ë¦¬
            if current_tokens + line_tokens > self.max_tokens and is_block_start and current_block:
                # í˜„ì¬ ë¸”ë¡ì„ sub-chunkë¡œ ì €ì¥
                block_content = '\n'.join(current_block)
                sub_chunk = self._create_sub_chunk(chunk, block_content, block_count)
                sub_chunks.append(sub_chunk)
                
                # ìƒˆ ë¸”ë¡ ì‹œì‘
                current_block = [line]
                current_tokens = line_tokens
                block_count += 1
            else:
                current_block.append(line)
                current_tokens += line_tokens
        
        # ë§ˆì§€ë§‰ ë¸”ë¡ ì²˜ë¦¬
        if current_block:
            block_content = '\n'.join(current_block)
            sub_chunk = self._create_sub_chunk(chunk, block_content, block_count)
            sub_chunks.append(sub_chunk)
        
        return sub_chunks if len(sub_chunks) > 1 else [chunk]
    
    def _create_sub_chunk(self, original_chunk: CodeChunk, content: str, block_index: int) -> CodeChunk:
        """ì›ë³¸ chunkì˜ sub-chunk ìƒì„±"""
        
        sub_chunk_id = f"{original_chunk.chunk_id}_block_{block_index}"
        
        return CodeChunk(
            chunk_id=sub_chunk_id,
            file_path=original_chunk.file_path,
            chunk_type=f"{original_chunk.chunk_type}_block",
            name=f"{original_chunk.name}_block_{block_index}",
            line_range=original_chunk.line_range,  # ì •í™•í•œ line ê³„ì‚°ì€ ë³µì¡í•˜ë¯€ë¡œ ì›ë³¸ ìœ ì§€
            content=content,
            parent=original_chunk.parent,
            base_classes=original_chunk.base_classes,
            decorators=original_chunk.decorators,
            tags=original_chunk.tags + ["sub_chunk"],
            complexity=original_chunk.complexity,
            docstring=original_chunk.docstring,
            dependencies=original_chunk.dependencies,
            is_async=original_chunk.is_async,
            is_generator=original_chunk.is_generator,
            token_count=len(self.encoding.encode(content))
        )
    
    # í—¬í¼ ë©”ì„œë“œë“¤
    
    def _build_signature(self, node: ast.FunctionDef) -> str:
        try:
            args = []
            for a in node.args.args:
                ann = self._annotation_to_str(a.annotation) if hasattr(a, 'annotation') else None
                args.append(f"{a.arg}: {ann}" if ann else a.arg)
            if node.args.vararg:
                args.append(f"*{node.args.vararg.arg}")
            for a in node.args.kwonlyargs:
                ann = self._annotation_to_str(a.annotation) if hasattr(a, 'annotation') else None
                args.append(f"{a.arg}: {ann}" if ann else a.arg)
            if node.args.kwarg:
                args.append(f"**{node.args.kwarg.arg}")
            ret = self._annotation_to_str(node.returns) if hasattr(node, 'returns') else None
            sig = f"({', '.join(args)})"
            if ret:
                sig += f" -> {ret}"
            return sig
        except Exception:
            return "()"

    def _annotation_to_str(self, ann) -> Optional[str]:
        if ann is None:
            return None
        try:
            if isinstance(ann, ast.Name):
                return ann.id
            if isinstance(ann, ast.Subscript):
                base = self._annotation_to_str(ann.value)
                sub = self._annotation_to_str(ann.slice)
                return f"{base}[{sub}]" if base and sub else base
            if isinstance(ann, ast.Attribute):
                return ann.attr
            if isinstance(ann, ast.Tuple):
                return ", ".join(filter(None, [self._annotation_to_str(e) for e in ann.elts]))
            if isinstance(ann, ast.Constant):
                return str(ann.value)
            return None
        except Exception:
            return None

    def _extract_parameters(self, node: ast.FunctionDef) -> List[str]:
        try:
            params = []
            for a in node.args.args:
                ann = self._annotation_to_str(a.annotation) if hasattr(a, 'annotation') else None
                params.append(f"{a.arg}: {ann}" if ann else a.arg)
            if node.args.vararg:
                params.append(f"*{node.args.vararg.arg}")
            for a in node.args.kwonlyargs:
                ann = self._annotation_to_str(a.annotation) if hasattr(a, 'annotation') else None
                params.append(f"{a.arg}: {ann}" if ann else a.arg)
            if node.args.kwarg:
                params.append(f"**{node.args.kwarg.arg}")
            return params
        except Exception:
            return []

    def _extract_raises(self, node: ast.AST) -> List[str]:
        raises = []
        try:
            for n in ast.walk(node):
                if isinstance(n, ast.Raise) and n.exc is not None:
                    if isinstance(n.exc, ast.Call) and isinstance(n.exc.func, ast.Name):
                        raises.append(n.exc.func.id)
                    elif isinstance(n.exc, ast.Name):
                        raises.append(n.exc.id)
        except Exception:
            pass
        return list(dict.fromkeys(raises))

    def _extract_calls(self, node: ast.AST) -> List[str]:
        calls = []
        try:
            for n in ast.walk(node):
                if isinstance(n, ast.Call):
                    if isinstance(n.func, ast.Name):
                        calls.append(n.func.id)
                    elif isinstance(n.func, ast.Attribute):
                        calls.append(n.func.attr)
        except Exception:
            pass
        return list(dict.fromkeys(calls))

    def _extract_data_flow(self, node: ast.AST) -> Tuple[List[Dict[str, str]], Dict[str, int]]:
        edges = []
        stats = {"assign": 0, "call": 0, "return": 0, "raise": 0}
        try:
            for n in ast.walk(node):
                if isinstance(n, ast.Assign):
                    src = self._expr_to_str(n.value)
                    for t in n.targets:
                        dst = self._expr_to_str(t)
                        edges.append({"op": "assign", "src": src, "dst": dst, "line": str(n.lineno)})
                        stats["assign"] += 1
                elif isinstance(n, ast.Call):
                    fname = self._expr_to_str(n.func)
                    edges.append({"op": "call", "src": fname, "dst": "(result)", "line": str(n.lineno)})
                    stats["call"] += 1
                elif isinstance(n, ast.Return):
                    val = self._expr_to_str(n.value)
                    edges.append({"op": "return", "src": val, "dst": "return", "line": str(n.lineno)})
                    stats["return"] += 1
                elif isinstance(n, ast.Raise):
                    exc = self._expr_to_str(n.exc)
                    edges.append({"op": "raise", "src": exc, "dst": "exception", "line": str(n.lineno)})
                    stats["raise"] += 1
        except Exception:
            pass
        # ìƒìœ„ Nê°œë§Œ ìš”ì•½(ENV ë¯¸ì‚¬ìš© ì‹œ 12ê°œ ê¸°ë³¸)
        summary = edges[:12]
        stats["edges"] = len(edges)
        return summary, stats

    def _expr_to_str(self, expr: ast.AST) -> str:
        try:
            if isinstance(expr, ast.Name):
                return expr.id
            if isinstance(expr, ast.Attribute):
                base = self._expr_to_str(expr.value)
                return f"{base}.{expr.attr}" if base else expr.attr
            if isinstance(expr, ast.Constant):
                return str(expr.value)
            if isinstance(expr, ast.Call):
                if isinstance(expr.func, ast.Name):
                    return expr.func.id
                if isinstance(expr.func, ast.Attribute):
                    return expr.func.attr
            if isinstance(expr, ast.BinOp):
                return "binop"
            if expr is None:
                return "None"
            return expr.__class__.__name__
        except Exception:
            return "expr"
    def _extract_imports(self, tree: ast.AST) -> List[str]:
        """import êµ¬ë¬¸ì—ì„œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ëª©ë¡ ì¶”ì¶œ"""
        imports = []
        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name.split('.')[0])  # ìµœìƒìœ„ íŒ¨í‚¤ì§€ë§Œ
            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    imports.append(node.module.split('.')[0])
        return list(set(imports))  # ì¤‘ë³µ ì œê±°
    
    def _get_decorator_name(self, decorator: ast.expr) -> str:
        """ë°ì½”ë ˆì´í„° ì´ë¦„ ì¶”ì¶œ"""
        if isinstance(decorator, ast.Name):
            return decorator.id
        elif isinstance(decorator, ast.Attribute):
            return decorator.attr
        elif isinstance(decorator, ast.Call):
            if isinstance(decorator.func, ast.Name):
                return decorator.func.id
            elif isinstance(decorator.func, ast.Attribute):
                return decorator.func.attr
        return "unknown"
    
    def _get_base_class_name(self, base: ast.expr) -> str:
        """ìƒì† í´ë˜ìŠ¤ ì´ë¦„ ì¶”ì¶œ"""
        if isinstance(base, ast.Name):
            return base.id
        elif isinstance(base, ast.Attribute):
            return base.attr
        return "unknown"
    
    def _is_generator_function(self, node: ast.FunctionDef) -> bool:
        """í•¨ìˆ˜ê°€ generatorì¸ì§€ ì²´í¬ (yield ì‚¬ìš© ì—¬ë¶€)"""
        for child in ast.walk(node):
            if isinstance(child, (ast.Yield, ast.YieldFrom)):
                return True
        return False
    
    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """ê°„ë‹¨í•œ ì‚¬ì´í´ë¡œë§¤í‹± ë³µì¡ë„ ê³„ì‚°"""
        complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.AsyncFor)):
                complexity += 1
            elif isinstance(child, ast.ExceptHandler):
                complexity += 1
        return complexity
    
    def _generate_overview_content(self, file_name: str, docstring: str, 
                                 classes: List[str], functions: List[str], 
                                 imports: List[str]) -> str:
        """íŒŒì¼ overview ë‚´ìš© ìƒì„±"""
        content = f"# {file_name}\n\n"
        
        if docstring:
            content += f"## ì„¤ëª…\n{docstring}\n\n"
        
        if classes:
            content += f"## í´ë˜ìŠ¤\n" + "\n".join(f"- {cls}" for cls in classes) + "\n\n"
        
        if functions:
            content += f"## í•¨ìˆ˜\n" + "\n".join(f"- {func}" for func in functions) + "\n\n"
        
        if imports:
            content += f"## ì˜ì¡´ì„±\n" + "\n".join(f"- {imp}" for imp in imports) + "\n\n"
        
        return content
    
    def _generate_tags_from_file(self, file_path: str, imports: List[str], 
                               classes: List[str], functions: List[str]) -> List[str]:
        """íŒŒì¼ ê¸°ë°˜ tags ìƒì„±"""
        tags = []
        
        # íŒŒì¼ëª… ê¸°ë°˜
        file_name = os.path.basename(file_path).replace('.py', '')
        tags.append(file_name)
        
        # ê²½ë¡œ ê¸°ë°˜
        path_parts = Path(file_path).parts
        for part in path_parts:
            if part not in ['.', '..', 'src', '__pycache__']:
                tags.append(part)
        
        # import ê¸°ë°˜
        common_libs = {
            'fastapi': ['api', 'web'],
            'requests': ['http', 'api'],
            'pandas': ['data', 'analysis'],
            'numpy': ['math', 'calculation'],
            'asyncio': ['async', 'concurrency'],
            'logging': ['log', 'debug'],
            'json': ['serialization', 'data'],
            'os': ['system', 'file'],
            'sys': ['system'],
            're': ['regex', 'pattern']
        }
        
        for imp in imports:
            if imp in common_libs:
                tags.extend(common_libs[imp])
            tags.append(imp)
        
        return list(set(tags))
    
    def _generate_tags_from_function(self, node: ast.FunctionDef, decorators: List[str], 
                                   is_async: bool, is_generator: bool) -> List[str]:
        """í•¨ìˆ˜ ê¸°ë°˜ tags ìƒì„±"""
        tags = []
        
        # í•¨ìˆ˜ëª… ê¸°ë°˜
        if 'test_' in node.name:
            tags.append('test')
        if 'validate' in node.name or 'check' in node.name:
            tags.append('validation')
        if 'process' in node.name or 'handle' in node.name:
            tags.append('processing')
        if 'get_' in node.name or 'fetch' in node.name:
            tags.append('getter')
        if 'set_' in node.name or 'update' in node.name:
            tags.append('setter')
        if 'create' in node.name or 'generate' in node.name:
            tags.append('creation')
        if 'delete' in node.name or 'remove' in node.name:
            tags.append('deletion')
        
        # ë°ì½”ë ˆì´í„° ê¸°ë°˜
        decorator_tags = {
            'property': 'property',
            'staticmethod': 'static',
            'classmethod': 'class_method',
            'abstractmethod': 'abstract',
            'cached_property': 'cached'
        }
        
        for dec in decorators:
            if dec in decorator_tags:
                tags.append(decorator_tags[dec])
        
        # íŠ¹ì„± ê¸°ë°˜
        if is_async:
            tags.append('async')
        if is_generator:
            tags.append('generator')
        
        return tags
    
    def _generate_tags_from_class(self, node: ast.ClassDef, base_classes: List[str], 
                                decorators: List[str]) -> List[str]:
        """í´ë˜ìŠ¤ ê¸°ë°˜ tags ìƒì„±"""
        tags = ['class']
        
        # í´ë˜ìŠ¤ëª… íŒ¨í„´ ê¸°ë°˜
        if node.name.endswith('Error') or node.name.endswith('Exception'):
            tags.append('exception')
        if node.name.endswith('Manager') or node.name.endswith('Controller'):
            tags.append('manager')
        if node.name.endswith('Service'):
            tags.append('service')
        if node.name.endswith('Model') or node.name.endswith('Schema'):
            tags.append('model')
        if 'Test' in node.name:
            tags.append('test')
        
        # ìƒì† ê¸°ë°˜
        common_bases = {
            'BaseModel': 'pydantic',
            'FastAPI': 'fastapi',
            'HTTPException': 'exception',
            'Enum': 'enum',
            'ABC': 'abstract'
        }
        
        for base in base_classes:
            if base in common_bases:
                tags.append(common_bases[base])
        
        return tags
    
    def _extract_docstring(self, node: ast.AST, lines: List[str], start_line: int) -> str:
        """í–¥ìƒëœ ë…ìŠ¤íŠ¸ë§ ì¶”ì¶œ (AST + í…ìŠ¤íŠ¸ ë¶„ì„ ê²°í•©)"""
        
        # 1. AST ë°©ì‹ìœ¼ë¡œ ì‹œë„
        ast_docstring = ast.get_docstring(node)
        if ast_docstring and ast_docstring.strip():
            return ast_docstring.strip()
        
        # 2. í…ìŠ¤íŠ¸ íŒŒì‹± ë°©ì‹ìœ¼ë¡œ ë³´ì™„
        try:
            # í•¨ìˆ˜/í´ë˜ìŠ¤ ì •ì˜ ë‹¤ìŒ ì¤„ë¶€í„° ì°¾ê¸°
            search_start = start_line + 1
            if search_start >= len(lines):
                return ""
            
            # ì²« ë²ˆì§¸ ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì°¾ê¸°
            for i in range(search_start, min(search_start + 10, len(lines))):
                line = lines[i].strip()
                
                # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„ ê±´ë„ˆë›°ê¸°
                if not line or line.startswith('#'):
                    continue
                
                # ë¬¸ìì—´ ë¦¬í„°ëŸ´ íŒ¨í„´ ë§¤ì¹­
                # """...""" ë˜ëŠ” '''...''' ë˜ëŠ” "..." ë˜ëŠ” '...'
                if (line.startswith('"""') or line.startswith("'''") or 
                    line.startswith('"') or line.startswith("'")):
                    
                    # ë©€í‹°ë¼ì¸ ë…ìŠ¤íŠ¸ë§ ì²˜ë¦¬
                    if line.startswith('"""') or line.startswith("'''"):
                        quote = '"""' if line.startswith('"""') else "'''"
                        docstring_lines = []
                        
                        # ê°™ì€ ì¤„ì— ëë‚˜ëŠ” ê²½ìš°
                        if line.count(quote) >= 2:
                            return line.replace(quote, '').strip()
                        
                        # ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ ê²½ìš°
                        docstring_lines.append(line.replace(quote, ''))
                        for j in range(i + 1, min(i + 20, len(lines))):
                            next_line = lines[j]
                            if quote in next_line:
                                docstring_lines.append(next_line.split(quote)[0])
                                break
                            docstring_lines.append(next_line)
                        
                        return '\n'.join(docstring_lines).strip()
                    
                    # ë‹¨ì¼ ë¼ì¸ ë…ìŠ¤íŠ¸ë§
                    else:
                        quote = '"' if line.startswith('"') else "'"
                        if line.count(quote) >= 2:
                            return line.split(quote)[1].strip()
                
                # ë‹¤ë¥¸ ì½”ë“œê°€ ë‚˜ì˜¤ë©´ ë…ìŠ¤íŠ¸ë§ì´ ì—†ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
                elif not line.startswith('@'):  # ë°ì½”ë ˆì´í„°ëŠ” ì œì™¸
                    break
            
            return ""
        
        except Exception as e:
            print(f"ë…ìŠ¤íŠ¸ë§ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return ast_docstring or ""

    def _generate_chunk_id(self, file_path: str, chunk_type: str, name: str) -> str:
        """ê³ ìœ í•œ chunk ID ìƒì„±"""
        content = f"{file_path}:{chunk_type}:{name}"
        return hashlib.md5(content.encode()).hexdigest()[:12]


def chunk_directory(directory_path: str, max_tokens: int = 600) -> List[CodeChunk]:
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  Python íŒŒì¼ì„ chunkë¡œ ë³€í™˜
    
    Args:
        directory_path: ë¶„ì„í•  ë””ë ‰í† ë¦¬ ê²½ë¡œ
        max_tokens: chunkë‹¹ ìµœëŒ€ í† í° ìˆ˜
        
    Returns:
        ëª¨ë“  íŒŒì¼ì˜ CodeChunk ë¦¬ìŠ¤íŠ¸
    """
    chunker = ASTChunker(max_tokens=max_tokens)
    all_chunks = []
    
    for root, dirs, files in os.walk(directory_path):
        # __pycache__ ë“± ì œì™¸
        dirs[:] = [d for d in dirs if not d.startswith('__')]
        
        for file in files:
            if file.endswith('.py'):
                file_path = os.path.join(root, file)
                print(f"ğŸ“„ Processing: {file_path}")
                
                chunks = chunker.chunk_file(file_path)
                all_chunks.extend(chunks)
                
                print(f"   âœ… Generated {len(chunks)} chunks")
    
    print(f"\nğŸ¯ ì´ {len(all_chunks)} ê°œì˜ chunk ìƒì„± ì™„ë£Œ")
    return all_chunks


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ìš©
    sample_dir = "/Users/roseline/projects/codemuse-backend/sample_code"
    chunks = chunk_directory(sample_dir)
    
    # ê²°ê³¼ ì¶œë ¥
    for chunk in chunks[:5]:  # ìƒìœ„ 5ê°œë§Œ ì¶œë ¥
        print(f"\n--- {chunk.chunk_type}: {chunk.name} ---")
        print(f"íŒŒì¼: {chunk.file_path}")
        print(f"ë¼ì¸: {chunk.line_range}")
        print(f"í† í°: {chunk.token_count}")
        print(f"íƒœê·¸: {chunk.tags}")
        print(f"ë‚´ìš© (ì²˜ìŒ 100ì): {chunk.content[:100]}...")
