# CodeMuse Frontend API ì—”ë“œí¬ì¸íŠ¸ ê°€ì´ë“œ (MD Chunk ê¸°ë°˜)

## ğŸ¯ í”„ë¡ íŠ¸ì—”ë“œìš© í•µì‹¬ ì—”ë“œí¬ì¸íŠ¸ (ì™„ì„±ëœ 2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸)

**âœ… ìµœì¢… ì™„ì„± ìƒíƒœ**: ê¸°ì¡´ íŒŒì¼ ë‹¨ìœ„ RAG â†’ **MD ì„¹ì…˜ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ì™„ì„±ëœ 2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸**

**ğŸ”„ ì£¼ìš” ì—…ë°ì´íŠ¸ (ìµœì‹ )**:
- **MD ë¬¸ì„œ ê¸°ë°˜**: Python ì†ŒìŠ¤ ëŒ€ì‹  êµ¬ì¡°í™”ëœ MD ì„¹ì…˜ ê²€ìƒ‰
- **ì™„ì „í•œ RAG ì´ˆê¸°í™”**: 0ê°œ ë¬¸ì„œì—ì„œ ì‹œì‘ (ê¹¨ë—í•œ ìƒíƒœ)
- **ì†ŒìŠ¤ êµ¬ì¡° ìœ ì§€**: `sample_code/` â†’ `generated_docs/` ë™ì¼ êµ¬ì¡°
- **í…œí”Œë¦¿ ë¶„ë¦¬**: Jinja2 ê¸°ë°˜ ì™¸ë¶€ í…œí”Œë¦¿ ì‹œìŠ¤í…œ

### **1. Chunk ê¸°ë°˜ RAG ê²€ìƒ‰** (Chunk ë‹¨ìœ„ ê²€ìƒ‰)
```
POST http://localhost:8003/api/v1/search
Content-Type: application/json

{
  "query": "ì‚¬ìš©ì ì§ˆë¬¸",
  "limit": 10,
  "chunk_type_filter": "overview|function|class",  // ì˜µì…˜: chunk íƒ€ì… í•„í„°
  "file_filter": ["analyzer.py", "validator.py"],  // ì˜µì…˜: íŒŒì¼ í•„í„°
  "include_metadata": true
}
```

**ì‘ë‹µ ì˜ˆì‹œ (Chunk ê¸°ë°˜):**
```json
{
  "query": "ì˜¤ë¥˜ ë¶„ì„ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
  "results": [
    {
      "chunk_id": "chunk_issue_detector_001",
      "content": "def detect_issues(self, code: str) -> List[Issue]:\n    \"\"\"ì½”ë“œ ì˜¤ë¥˜ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤\"\"\"\n    issues = []\n    # 7ê°€ì§€ ì˜¤ë¥˜ ìœ í˜• ê²€ì¶œ ë¡œì§...",
      "score": 0.92,
      "metadata": {
        "filename": "issue_detector.py",
        "chunk_type": "function",
        "name": "detect_issues",
        "line_range": "45-78",
        "complexity": 8,
        "tags": ["error_detection", "analysis", "validation"],
        "folder_priority": 95,
        "is_async": false
      }
    },
    {
      "chunk_id": "chunk_issue_detector_overview",
      "content": "IssueDetector í´ë˜ìŠ¤ëŠ” Python ì½”ë“œì—ì„œ 7ê°€ì§€ ì£¼ìš” ì˜¤ë¥˜ ìœ í˜•ì„ ê²€ì¶œí•©ë‹ˆë‹¤:\n1. íƒ€ì… ë¶ˆì¼ì¹˜\n2. ì¤‘ë³µ ì½”ë“œ...",
      "score": 0.88,
      "metadata": {
        "filename": "issue_detector.py", 
        "chunk_type": "overview",
        "name": "IssueDetector",
        "dependencies": ["ast", "typing", "logging"],
        "folder_priority": 95
      }
    }
  ],
  "total_results": 15,
  "search_strategy": {
    "overview_chunks": 3,
    "function_chunks": 7,
    "hybrid_score": true
  },
  "search_time": 0.12
}
```

### **2. LLM ì±„íŒ…** (ëŒ€í™”, 8004)

#### 2.1 ì±„íŒ… ì„¸ì…˜ ìƒì„±
```
POST http://localhost:8004/api/v1/chat/sessions
Content-Type: application/json

{
  "title": "ìƒˆ ì±„íŒ…"
}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "id": "session_123",
  "title": "ìƒˆ ì±„íŒ…",
  "created_at": "2024-01-01T00:00:00Z",
  "messages": []
}
```

#### 2.2 ë©”ì‹œì§€ ì „ì†¡
```
POST http://localhost:8004/api/v1/chat/sessions/{session_id}/messages
Content-Type: application/json

{
  "message": "ì‚¬ìš©ì ì§ˆë¬¸",
  "model": "gpt-3.5-turbo",
  "context": {
    "search_results": [ê²€ìƒ‰ëœ ë¬¸ì„œë“¤]
  }
}
```

**ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "message": "Pythonì—ì„œ í•¨ìˆ˜ëŠ” def í‚¤ì›Œë“œë¡œ ì •ì˜í•©ë‹ˆë‹¤...",
  "session_id": "session_123",
  "model": "gpt-3.5-turbo",
  "usage": {
    "prompt_tokens": 150,
    "completion_tokens": 200,
    "total_tokens": 350
  },
  "response_time": 2.5
}
```

#### 2.3 ë©”ì‹œì§€ ëª©ë¡ ì¡°íšŒ
```
GET http://localhost:8004/api/v1/chat/sessions/{session_id}/messages
```

#### 2.4 ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ
```
GET http://localhost:8004/api/v1/chat/sessions
```

### **3. í†µí•© ì›Œí¬í”Œë¡œìš°** (2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸, 8006) â­ **ë©”ì¸ API**
```
POST http://localhost:8006/workflow
Content-Type: application/json

{
  "query": "ì‚¬ìš©ì ì§ˆë¬¸",
  "use_rag": true,
  "model": "gpt-4",
  "max_chunks": 5,           // ê²€ìƒ‰í•  ìµœëŒ€ chunk ìˆ˜
  "include_overview": true   // overview chunk í¬í•¨ ì—¬ë¶€
}
```

**ì‘ë‹µ ì˜ˆì‹œ (2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸):**
```json
{
  "query": "ì–´ë–¤ ì˜¤ë¥˜ ìœ í˜•ë“¤ì„ ë¶„ì„í•˜ê³  ìˆë‚˜ìš”?",
  "use_rag": true,
  "search_strategy": {
    "overview_results": 2,
    "function_chunks": 3,
    "filtered_files": ["issue_detector.py", "validator.py"],
    "search_keywords": ["ë¶„ì„", "error", "detection", "issue_detector"],
    "total_chunks_found": 5
  },
  "rag_results": [
    {
      "chunk_id": "chunk_issue_detector_overview",
      "content": "IssueDetectorëŠ” 7ê°€ì§€ ì˜¤ë¥˜ ìœ í˜•ì„ ê²€ì¶œí•©ë‹ˆë‹¤:\n1. íƒ€ì… ë¶ˆì¼ì¹˜\n2. ì¤‘ë³µ ì½”ë“œ\n3. ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë³€ìˆ˜...",
      "metadata": {
        "filename": "issue_detector.py",
        "chunk_type": "overview",
        "folder_priority": 95
      }
    }
  ],
  "llm_summary": null,
  "llm_response": "CodeMuseëŠ” í˜„ì¬ 7ê°€ì§€ ì£¼ìš” ì˜¤ë¥˜ ìœ í˜•ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤:\n\n1. **íƒ€ì… ë¶ˆì¼ì¹˜**: ë³€ìˆ˜ë‚˜ í•¨ìˆ˜ì˜ íƒ€ì…ì´ ë§ì§€ ì•ŠëŠ” ê²½ìš°\n2. **ì¤‘ë³µ ì½”ë“œ**: ë™ì¼í•˜ê±°ë‚˜ ìœ ì‚¬í•œ ì½”ë“œê°€ ë°˜ë³µë˜ëŠ” ê²½ìš°\n3. **ì‚¬ìš©ë˜ì§€ ì•ŠëŠ” ë³€ìˆ˜**: ì •ì˜í–ˆì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ë³€ìˆ˜ë“¤\n4. **ìˆœí™˜ ì°¸ì¡°**: ëª¨ë“ˆ ê°„ ìˆœí™˜ ì˜ì¡´ì„± ë¬¸ì œ\n5. **ë³µì¡ë„ ì´ˆê³¼**: í•¨ìˆ˜ë‚˜ í´ë˜ìŠ¤ì˜ ë³µì¡ë„ê°€ ë„ˆë¬´ ë†’ì€ ê²½ìš°\n6. **ë„¤ì´ë° ê·œì¹™ ìœ„ë°˜**: Python PEP8 ë„¤ì´ë° ì»¨ë²¤ì…˜ ìœ„ë°˜\n7. **ë³´ì•ˆ ì·¨ì•½ì **: ì ì¬ì ì¸ ë³´ì•ˆ ë¬¸ì œê°€ ìˆëŠ” ì½”ë“œ íŒ¨í„´\n\nì´ëŸ¬í•œ ë¶„ì„ì€ IssueDetector í´ë˜ìŠ¤ë¥¼ í†µí•´ ìë™í™”ë˜ì–´ ìˆìœ¼ë©°, AST íŒŒì‹±ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ê²€ì¶œì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.",
  "workflow_time": 2.8,
  "services_used": [
    "LLM Keyword Extraction",
    "RAG Engine", 
    "LLM Summary",
    "LLM Chat"
  ]
}
```

### **4. ë¬¸ì„œ ìƒì„± ë° ì—…ë°ì´íŠ¸** (Document Generator, 8001) â­ **í”„ë¡ íŠ¸ì—”ë“œ í•µì‹¬**
```
POST http://localhost:8001/api/v1/documents/generate
Content-Type: application/json
```

**ì£¼ìš” ê¸°ëŠ¥**:
- ì†ŒìŠ¤ì½”ë“œ â†’ MD ë¬¸ì„œ ìƒì„± (32ê°œ íŒŒì¼)
- MD ì„¹ì…˜ë³„ RAG ìë™ ì—…ë¡œë“œ (### ê¸°ì¤€ ë¶„í• )
- ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ë¡œ ì¦‰ì‹œ ì‘ë‹µ

**ì‘ë‹µ ì˜ˆì‹œ**:
```json
{
  "status": "started",
  "message": "ë¬¸ì„œ ì—…ë°ì´íŠ¸ê°€ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œê¹Œì§€ ì•½ 30ì´ˆ ì†Œìš”ë©ë‹ˆë‹¤.",
  "docs_created": 0,
  "docs_uploaded": 0, 
  "processing_time": 0.0
}
```

ë¹„ê³ : ë³„ë„ ìƒíƒœ í´ë§ APIëŠ” ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìƒì„± í˜¸ì¶œ í›„ `GET http://localhost:8003/health` ì˜ `documents_count` ì¦ê°€ë¡œ í™•ì¸í•˜ì„¸ìš”.

### **5. í—¬ìŠ¤ ì²´í¬ ë° ì„œë¹„ìŠ¤ ìƒíƒœ**
```
GET http://localhost:8003/health  # RAG Engine (MD Chunk ê¸°ë°˜)
GET http://localhost:8004/health  # LLM Chat 
GET http://localhost:8006/health  # Workflow Orchestrator (2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
GET http://localhost:8001/health  # Document Generator Service
GET http://localhost:8006/services/status  # í†µí•© ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
```

**ì„œë¹„ìŠ¤ ìƒíƒœ ì‘ë‹µ ì˜ˆì‹œ:**
```json
{
  "rag_service": "healthy",
  "llm_service": "healthy", 
  "workflow_status": "operational",
  "chunk_system": "active",
  "pipeline_mode": "2-stage",
  "last_updated": "2024-01-01T00:00:00Z"
}
```

## ğŸš€ í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ ì‹œë‚˜ë¦¬ì˜¤ (MD Chunk ê¸°ë°˜)

### **ì‹œë‚˜ë¦¬ì˜¤ 0: ë¬¸ì„œ ìƒì„± ë° RAG ì—…ë¡œë“œ** â­ **í•„ìˆ˜ ì²« ë‹¨ê³„**
```javascript
// ë¬¸ì„œ ìƒì„± + RAG ì—…ë¡œë“œ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë²„íŠ¼ í´ë¦­)
const generateAndUploadDocuments = async () => {
  // 1. ë¬¸ì„œ ìƒì„± ì‹œì‘
  const response = await fetch('http://localhost:8001/api/v1/documents/generate', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'}
  });
  
  const result = await response.json();
  console.log('ë¬¸ì„œ ìƒì„± ê²°ê³¼:', result.status);
  
  // 2. ìƒì„± ì—¬ë¶€ í™•ì¸ (RAG ë¬¸ì„œ ìˆ˜ í™•ì¸)
  const healthResp = await fetch('http://localhost:8003/health');
  const health = await healthResp.json();
  console.log('RAG documents_count:', health.documents_count);
};

// Vue 3 ì˜ˆì‹œ
const { ref } = Vue;
export default {
  setup() {
    const isGenerating = ref(false);
    const documentsCount = ref(0);
    const generationStatus = ref('idle'); // idle, processing, ready
    
    const handleGenerateDocuments = async () => {
      isGenerating.value = true;
      generationStatus.value = 'processing';
      
      try {
        await generateAndUploadDocuments();
        generationStatus.value = 'ready';
      } catch (error) {
        console.error('ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨:', error);
        generationStatus.value = 'error';
      } finally {
        isGenerating.value = false;
      }
    };
    
    return {
      isGenerating,
      documentsCount,
      generationStatus,
      handleGenerateDocuments
    };
  }
};
```

### **ì‹œë‚˜ë¦¬ì˜¤ 1: MD Chunk ê¸°ë°˜ ê²€ìƒ‰** 
```javascript
// Chunk ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ê²€ìƒ‰
const searchChunks = async (query) => {
  const response = await fetch('http://localhost:8003/api/v1/search', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
      query: query,
      top_k: 10,
      chunk_type_filter: "overview|function",  // overviewì™€ function chunkë§Œ
      include_metadata: true
    })
  });
  
  const results = await response.json();
  
  // Chunk ë©”íƒ€ë°ì´í„° í™œìš©
  results.results.forEach(chunk => {
    console.log(`[${chunk.metadata.chunk_type}] ${chunk.metadata.name}`);
    console.log(`ë³µì¡ë„: ${chunk.metadata.complexity || 'N/A'}`);
    console.log(`íƒœê·¸: ${chunk.metadata.tags?.join(', ')}`);
  });
  
  return results;
};
```

### **ì‹œë‚˜ë¦¬ì˜¤ 2: 2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸** â­ **ê¶Œì¥**
```javascript
// ê°€ì¥ ê°„ë‹¨í•˜ê³  ê°•ë ¥í•œ ë°©ë²•
const askQuestion = async (userQuery) => {
  const response = await fetch('http://localhost:8006/workflow', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({
      query: userQuery,
      use_rag: true,
      model: 'gpt-4',
      max_chunks: 5,
      include_overview: true
    })
  });
  
  const result = await response.json();
  
  // ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ë³„ ì •ë³´ í™œìš©
  console.log('ğŸ” ê²€ìƒ‰ ì „ëµ:', result.search_strategy);
  console.log('ğŸ“ LLM ìš”ì•½:', result.llm_summary);
  console.log('ğŸ¤– ìµœì¢… ë‹µë³€:', result.llm_response);
  console.log('â±ï¸ ì²˜ë¦¬ ì‹œê°„:', result.workflow_time);
  
  return result;
};

// ì‚¬ìš© ì˜ˆì‹œ
askQuestion("ì–´ë–¤ ì˜¤ë¥˜ë“¤ì„ ë¶„ì„í•˜ê³  ìˆë‚˜ìš”?")
  .then(result => {
    // UIì— ê²°ê³¼ í‘œì‹œ
    displaySearchStrategy(result.search_strategy);
    displayLLMSummary(result.llm_summary);  
    displayFinalAnswer(result.llm_response);
  });
```

### **ì‹œë‚˜ë¦¬ì˜¤ 3: ì‹¤ì‹œê°„ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ì¶”ì **
```javascript
// Vue 3 Composition API ì˜ˆì‹œ
import { ref, reactive } from 'vue'

export const useWorkflowStatus = () => {
  const isProcessing = ref(false)
  const currentStep = ref('idle')  // idle, keywords, search, summary, response
  const searchStrategy = reactive({})
  const llmSummary = ref('')
  const finalResponse = ref('')
  
  const executeWorkflow = async (query) => {
    isProcessing.value = true
    currentStep.value = 'keywords'
    
    try {
      const response = await fetch('http://localhost:8006/workflow', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({
          query,
          use_rag: true,
          model: 'gpt-4'
        })
      })
      
      const result = await response.json()
      
      // ë‹¨ê³„ë³„ ìƒíƒœ ì—…ë°ì´íŠ¸
      currentStep.value = 'search'
      Object.assign(searchStrategy, result.search_strategy)
      
      currentStep.value = 'summary'
      llmSummary.value = result.llm_summary || ''
      
      currentStep.value = 'response'
      finalResponse.value = result.llm_response
      
      currentStep.value = 'completed'
      
    } catch (error) {
      console.error('ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì‹¤íŒ¨:', error)
      currentStep.value = 'error'
    } finally {
      isProcessing.value = false
    }
  }
  
  return {
    isProcessing,
    currentStep,
    searchStrategy,
    llmSummary,
    finalResponse,
    executeWorkflow
  }
}
```

### **ì‹œë‚˜ë¦¬ì˜¤ 4: Chunk íƒìƒ‰ê¸° êµ¬í˜„**
```javascript
// Chunk ë©”íƒ€ë°ì´í„° ê¸°ë°˜ í•„í„°ë§ ë° ì •ë ¬
const ChunkExplorer = {
  async getChunksByType(chunkType) {
    const response = await fetch('http://localhost:8003/api/v1/search', {
      method: 'POST',
      headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({
        query: '*',  // ì „ì²´ ê²€ìƒ‰
        chunk_type_filter: chunkType,
        top_k: 50
      })
    });
    return await response.json();
  },
  
  async getChunksByComplexity(minComplexity = 5) {
    // ë³µì¡ë„ê°€ ë†’ì€ í•¨ìˆ˜ë“¤ ì°¾ê¸°
    const chunks = await this.getChunksByType('function');
    return chunks.results.filter(chunk => 
      chunk.metadata.complexity >= minComplexity
    ).sort((a, b) => b.metadata.complexity - a.metadata.complexity);
  },
  
  async getChunksByTags(tags) {
    // íŠ¹ì • íƒœê·¸ë¥¼ ê°€ì§„ chunkë“¤ ì°¾ê¸°
    const response = await fetch('http://localhost:8003/api/v1/search', {
      method: 'POST', 
      headers: {'Content-Type': 'application/json'},
      body: JSON.stringify({
        query: tags.join(' '),  // íƒœê·¸ë“¤ì„ ê²€ìƒ‰ì–´ë¡œ ì‚¬ìš©
        top_k: 30
      })
    });
    return await response.json();
  }
};
```

## ğŸ“‹ í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜
```bash
# .env íŒŒì¼ì— ì„¤ì •
OPENAI_API_KEY=your-openai-key
ANTHROPIC_API_KEY=your-anthropic-key
```

## ğŸ”§ CORS ì„¤ì •
ëª¨ë“  ì„œë¹„ìŠ¤ì—ì„œ CORSê°€ í—ˆìš©ë˜ì–´ ìˆì–´ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤.

## ğŸ“ ì—ëŸ¬ ì²˜ë¦¬
```javascript
try {
  const response = await fetch('http://localhost:8004/api/v1/chat/sessions', {
    method: 'POST',
    headers: {'Content-Type': 'application/json'},
    body: JSON.stringify({title: 'My Chat'})
  });
  
  if (!response.ok) {
    throw new Error(`HTTP error! status: ${response.status}`);
  }
  
  const data = await response.json();
  console.log(data);
} catch (error) {
  console.error('API í˜¸ì¶œ ì‹¤íŒ¨:', error);
}
```

## ğŸ¯ MVP í”„ë¡ íŠ¸ì—”ë“œ í”Œë¡œìš° (MD Chunk ê¸°ë°˜)

### **ì™„ì „í•œ í”Œë¡œìš°** (ê¶Œì¥ - í•„ìˆ˜ 2ë‹¨ê³„)
```
STEP 1: ë¬¸ì„œ ìƒì„± (í•„ìˆ˜ - ìµœì´ˆ 1íšŒ)
    â†“
POST /api/v1/demo/update-documents (ë¬¸ì„œ ìƒì„± + RAG ì—…ë¡œë“œ)
    â”œâ”€ ì†ŒìŠ¤ì½”ë“œ â†’ 32ê°œ MD íŒŒì¼ ìƒì„±
    â”œâ”€ MD íŒŒì¼ â†’ ### ê¸°ì¤€ ì„¹ì…˜ ë¶„í• 
    â”œâ”€ ì„¹ì…˜ë³„ ë©”íƒ€ë°ì´í„° ìƒì„±
    â””â”€ RAG ë²¡í„°í™” ì €ì¥ (462ê°œ chunk)
    â†“
í´ë§ìœ¼ë¡œ ì™„ë£Œ ëŒ€ê¸° (documents_count > 0)
    â†“
STEP 2: ëŒ€í™” ì‹œì‘ (ë°˜ë³µ ê°€ëŠ¥)
    â†“
POST /workflow (ì™„ì„±ëœ 2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸)
    â”œâ”€ 1ë‹¨ê³„: LLM í‚¤ì›Œë“œ ì¶”ì¶œ ("ë¬´ìŠ¨ ì‹œìŠ¤í…œ?" â†’ ["system", "project"])
    â”œâ”€ 2ë‹¨ê³„: MD Chunk ê²€ìƒ‰ (project_summary â†’ ê´€ë ¨ MD ì„¹ì…˜)
    â”œâ”€ 3ë‹¨ê³„: LLM ìš”ì•½ (ë‹¤ìˆ˜ chunkì¸ ê²½ìš°)
    â””â”€ 4ë‹¨ê³„: ìµœì¢… LLM ì‘ë‹µ ("Rule Analyzer ì‹œìŠ¤í…œì…ë‹ˆë‹¤")
    â†“
ê²°ê³¼ í‘œì‹œ (search_strategy + llm_summary + llm_response)
```

### **ê³ ê¸‰ í”Œë¡œìš°** (Chunk íƒìƒ‰ í¬í•¨)
```
ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    â†“
POST /workflow (2ë‹¨ê³„ íŒŒì´í”„ë¼ì¸)
    â†“
search_strategy ë¶„ì„
    â”œâ”€ overview_chunks: Xê°œ
    â”œâ”€ function_chunks: Yê°œ  
    â””â”€ filtered_files: [íŒŒì¼ëª©ë¡]
    â†“
Chunk ìƒì„¸ ì •ë³´ í‘œì‹œ
    â”œâ”€ ë©”íƒ€ë°ì´í„° (ë³µì¡ë„, íƒœê·¸, ë¼ì¸ë²”ìœ„)
    â”œâ”€ Mermaid ì°¨íŠ¸ ë Œë”ë§
    â””â”€ ì½”ë“œ ì‹ íƒìŠ¤ í•˜ì´ë¼ì´íŒ…
    â†“
LLM ì‘ë‹µ + ê´€ë ¨ Chunk í‘œì‹œ
```

### **í•„ìˆ˜ API (MVP)**
1. â­ **POST /api/v1/demo/update-documents** - ë¬¸ì„œ ìƒì„± + RAG ì—…ë¡œë“œ (ìµœì´ˆ í•„ìˆ˜)
2. **GET /api/v1/demo/status** - ë¬¸ì„œ ìƒì„± ìƒíƒœ í™•ì¸ (í´ë§ìš©)
3. â­ **POST /workflow** - ì™„ì„±ëœ 2ë‹¨ê³„ LLM íŒŒì´í”„ë¼ì¸ (ë©”ì¸ ëŒ€í™”)
4. **GET /services/status** - ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸

### **ì„ íƒì  API (í™•ì¥)**
5. **POST /api/v1/search** - ì§ì ‘ MD Chunk ê²€ìƒ‰ (íƒìƒ‰ê¸°ìš©)
6. **POST /api/v1/chat/sessions** - ì±„íŒ… ì„¸ì…˜ ê´€ë¦¬
7. **GET /health** (ê° ì„œë¹„ìŠ¤) - ê°œë³„ ì„œë¹„ìŠ¤ ìƒíƒœ

**ë‹¨ 4ê°œ í•µì‹¬ APIë¡œ ì™„ì „í•œ MD ê¸°ë°˜ í”„ë¡ íŠ¸ì—”ë“œ ì™„ì„±!** ğŸš€

**ğŸ¯ ê°œë°œ ìˆœì„œ**:
1. ë¬¸ì„œ ìƒì„± ë²„íŠ¼ â†’ POST `/api/v1/demo/update-documents`
2. ìƒíƒœ í´ë§ â†’ GET `/api/v1/demo/status`
3. ëŒ€í™” ì¸í„°í˜ì´ìŠ¤ â†’ POST `/workflow`
4. ì‘ë‹µ í‘œì‹œ (search_strategy + llm_summary + llm_response)

---

## ğŸ”§ ì¶”ê°€ Chunk API ì—”ë“œí¬ì¸íŠ¸

### **Chunk ë©”íƒ€ë°ì´í„° ì¡°íšŒ**
```
GET http://localhost:8003/api/v1/chunks/metadata
```

### **íŠ¹ì • Chunk ìƒì„¸ ì¡°íšŒ**  
```
GET http://localhost:8003/api/v1/chunks/{chunk_id}
```

### **Chunk ì—…ë¡œë“œ (ë¬¸ì„œ ìƒì„± í›„)**
```
POST http://localhost:8003/api/v1/chunks/upload
Content-Type: application/json

{
  "chunks": [chunkë°ì´í„°ë°°ì—´],
  "collection_name": "codemuse_chunks"
}
```
